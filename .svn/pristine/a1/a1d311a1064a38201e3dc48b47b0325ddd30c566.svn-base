/*
 * image_test.cpp
 *
 *  Created on: Sep 5, 2012
 *      Author: guillem
 */

#include <imageplus/core/image_signal.hpp>
#include <imageplus/core/video_signal.hpp>
#include <imageplus/core/colorspace_converter.hpp>

#include <imageplus/optical_flow/flow_io.hpp>
#include <imageplus/optical_flow/occlusions/photo_consistency_error.hpp>
#include <imageplus/optical_flow/occlusions/flow_variation_error.hpp>
#include <imageplus/optical_flow/occlusions/reverse_endpoint_error.hpp>
#include <imageplus/optical_flow/occlusions/reverse_angle_error.hpp>
#include <imageplus/optical_flow/occlusions/bijective_error.hpp>

#include <imageplus/math/algebra/robust_regression.hpp>

#include <boost/filesystem.hpp>
#include <imageplus/toolbox/tictoc.hpp>
#include <iostream>
#include <iomanip>
#include <fstream>
#include <vector>
#include <set>

using namespace imageplus;

#define uint64 imageplus::uint64

typedef VideoSignal<float64,3> 																		VideoType;
typedef VideoSignal<float64,3>::ImageType															FrameType;
typedef ImageSignal<float64,1>																		ConfidenceMapType;
typedef VideoSignal<float64,2>																		OpticalFlowType;
typedef OpticalFlowType::ImageType																	OpticalFlowFrame;


typedef VideoType::coord_type 																		coord3d;

// The vector is of the same type
typedef VideoType::value_type																		lab_type;
typedef VideoType::value_type																		rgb_type;

FrameType convert_map_to_image(ImageSignal<float64,1>& s) {
	typedef ImageSignal<float64,1>::coord_type 	coord2d;
	FrameType res(s.sizes());
	for (ImageSignal<float64,1>::iterator p = s.begin(); p!=s.end(); ++p) {
		coord2d pos = p.pos();
		float64 value = (*p)(0); if (value < 0) value=0;
		res(pos) = value*rgb_type(255,255,255);
	}

	return res;
}

void precision_recall(ConfidenceMapType& result, ConfidenceMapType& gt, uint64 nth, std::string path) {
	std::ofstream ofs(path.c_str());

	float64 div =1.0/nth;
	for (float64 th = div; th < 1; th+=div) {
		float64 tp = 0;
		float64 tn = 0;
		float64 fp = 0;
		float64 fn = 0;
		for (ConfidenceMapType::iterator p = result.begin(); p != result.end(); ++p) {
			ConfidenceMapType::coord_type pos = p.pos();
			float64 v = (*p)(0);
			if (v < 0) continue;
			v = ((*p)(0) > th) ? 1 : 0;
			float64 v_gt = gt(pos)(0);
			if (v ==v_gt) {
				if (v == 0) tn++;
				if (v == 1) tp++;
			} else {
				if (v == 0) fn++;
				if (v == 1) fp++;
			}
		}
		float64 p = tp / (tp + fp);
		float64 r = tp / (tp + fn);
		ofs << th << " " << p << " " << r << " " << (2*p*r)/(p+r) << std::endl;
	}
}

int main(int argc, char* argv[]) {

	std::istringstream spath(argv[1]);

	std::string path; spath >> path;
	std::string result;

	uint64 N = 13;
	uint64 train[] = {9,10,17,18,19,22,24,27,29,30,39,49,50};

	std::string train_data_path = path + "/train_data.txt";
	//std::ofstream ofs(train_data_path.c_str());

	std::vector<ConfidenceMapType> photo(51);
	std::vector<ConfidenceMapType> var(51);
	std::vector<ConfidenceMapType> ep(51);
	std::vector<ConfidenceMapType> epa(51);
	std::vector<ConfidenceMapType> bij(51);
	std::vector<ConfidenceMapType> occ_gt(51);
	uint64 Nth = 1000;

	for (uint64 i = 0; i < N; i++) {
		std::cout << "Gathering data for seq " << train[i] << ", is " << i+1 << "/" << N << std::endl;
		FrameType img1,img2,mask;
		std::ostringstream os;
		std::string seq_path;
		os << path << "/" << train[i]; seq_path = os.str(); os.str("");
		os << seq_path << "/frames/frame000.png"; img1.read(os.str()); os.str("");
		os << seq_path << "/frames/frame001.png"; img2.read(os.str()); os.str("");
		//os << seq_path << "/flow.png"; gd.read(os.str()); os.str("");
		os << seq_path << "/mask.jpg"; mask.read(os.str()); os.str("");

		OpticalFlowFrame fwd(img1.size_x(), img2.size_y());
		OpticalFlowFrame bwd(img1.size_x(), img2.size_y());
		OpticalFlowFrame gt_flow(img1.size_x(), img2.size_y());

		os << seq_path << "/flows/flow_0_1.flo"; optical_flow::read_optical_flow(fwd, os.str()); os.str("");
		os << seq_path << "/flows/flow_1_0.flo"; optical_flow::read_optical_flow(bwd, os.str()); os.str("");
		os << seq_path << "/1_2.flo"; optical_flow::read_optical_flow(gt_flow, os.str()); os.str("");

		photo[train[i]] 	= optical_flow::photo_consistency_error(img1,img2,fwd);
		var[train[i]] 		= optical_flow::flow_variation_error(fwd);
		ep[train[i]]		= optical_flow::reverse_endpoint_error(fwd,bwd);
		epa[train[i]]		= optical_flow::reverse_angle_error(fwd,bwd);
		bij[train[i]]		= optical_flow::bijective_error(img1,img2,fwd);

		ImageSignal<float64,3> photo_img = convert_map_to_image(photo[train[i]]);
		ImageSignal<float64,3> var_img = convert_map_to_image(var[train[i]]);
		ImageSignal<float64,3> ep_img = convert_map_to_image(ep[train[i]]);
		ImageSignal<float64,3> epa_img = convert_map_to_image(epa[train[i]]);
		ImageSignal<float64,3> bij_img = convert_map_to_image(bij[train[i]]);

		os << seq_path << "/photo_consistency.png"; photo_img.write(os.str()); os.str("");
		os << seq_path << "/flow_variation.png"; var_img.write(os.str()); os.str("");
		os << seq_path << "/reverse_endpoint.png"; ep_img.write(os.str()); os.str("");
		os << seq_path << "/reverse_angle.png"; epa_img.write(os.str()); os.str("");
		os << seq_path << "/bijectivity.png"; bij_img.write(os.str()); os.str("");

		ImageSignal<float64,1> occ_sig(img1.size_x(), img2.size_y());
		uint64 occs = 0;
		for (FrameType::iterator p = img1.begin(); p != img1.end(); ++p) {
			FrameType::coord_type pos = p.pos();
			if (gt_flow(pos)(0) > 1e3 && mask(pos).isZero()) {
				occ_sig(pos)(0) = 1;
				//ofs << train[i] << " " << photo[train[i]](pos)(0) << " " << var[train[i]](pos)(0) << " " << ep[train[i]](pos)(0) << " " << epa[train[i]](pos)(0) << " " << bij[train[i]](pos)(0) << " " << 1 << std::endl;
				occs++;
			} else
				occ_sig(pos)(0) = 0;
		}
		//to train we choose the points 50%, 50%

		/*ImageSignal<float64,1> done(img1.size_x(), img2.size_y());
		uint64 sx = img1.size_x();
		uint64 sy = img2.size_y();
		for (uint64 k = 0; k < occs; k++) {
			uint64 x = 0;
			uint64 y = 0;
			do {
				x = rand() % sx;
				y = rand() % sy;
			} while (done(x,y)(0) == 1 || occ_sig(x,y)(0) == 1 || bij[train[i]](x,y)(0) < 0);

			done(x,y)(0) = 1;
			ofs << train[i] << " " << photo[train[i]](x,y)(0) << " " << var[train[i]](x,y)(0) << " " << ep[train[i]](x,y)(0) << " " << epa[train[i]](x,y)(0) << " " << bij[train[i]](x,y)(0) << " " << 0 << std::endl;
		}*/

		occ_gt[train[i]] = occ_sig;

		ImageSignal<float64,3> occ_gt_img = convert_map_to_image(occ_sig);
		os << seq_path << "/occlusion_gt.png"; occ_gt_img.write(os.str()); os.str("");

		// output the performance for that image
		/*os << seq_path << "/occ_photo.txt"; precision_recall(photo[train[i]],occ_sig,Nth,os.str()); os.str("");
		os << seq_path << "/occ_var.txt"; precision_recall(var[train[i]],occ_sig,Nth,os.str()); os.str("");
		os << seq_path << "/occ_ep.txt"; precision_recall(ep[train[i]],occ_sig,Nth,os.str()); os.str("");
		os << seq_path << "/occ_epa.txt"; precision_recall(epa[train[i]],occ_sig,Nth,os.str()); os.str("");
		os << seq_path << "/occ_bij.txt"; precision_recall(bij[train[i]],occ_sig,Nth,os.str()); os.str("");*/
	}
	//ofs.close();

	//Put the leave-one-out experiments
	uint64 Ntest = 6;
	std::vector<std::set<uint64> > test(Ntest);
	test[0].insert(9); test[0].insert(10);  test[0].insert(22);  test[0].insert(24);
	test[1].insert(17);
	test[2].insert(18); test[2].insert(19);
	test[3].insert(27); test[3].insert(29);
	test[4].insert(30); test[4].insert(39);
	test[5].insert(49); test[5].insert(50);


	std::ifstream train_data_file(train_data_path.c_str());
	uint64 is_occ;
	std::vector<uint64> num_samples(51,0);
	std::vector<float64> f(6);

	std::vector<std::vector<float64> > train_data;
	std::vector<float64> o;

	uint64 n =0;

	while (train_data_file >> f[0] >> f[1] >> f[2] >> f[3] >> f[4] >> f[5] >> is_occ) {
		train_data.push_back(f);
		num_samples[f[0]]++;
		o.push_back(is_occ);
		n++;
	}

	std::cout << "There are a total of " << n << " training samples " << std::endl;

	for (uint64 i = 0; i < Ntest; i++) {
		uint64 Nsamples = 0;
		uint64 D = 5;
		for (uint64 k = 0; k < N; k++)
			if (test[i].find(train[k]) == test[i].end())
				Nsamples+=num_samples[train[k]];

		std::cout << "Test case with " << Nsamples << std::endl;

		cv::Mat samples(Nsamples,D, CV_32FC1);
		cv::Mat output(Nsamples,1, CV_32FC1);
		cv::Mat test_sample(1,D, CV_32FC1);
		cv::Mat missing = cv::Mat::zeros(1,100,CV_8UC1);

		math::Matrix X(Nsamples,D+1);
		math::Vector y(Nsamples);

		int n_sample = 0;
		float64 occs = 0;
		float64 non_occs = 0;
		for (uint64 k = 0; k < train_data.size(); k++) {
			if (test[i].find(train_data[k][0]) == test[i].end()) {

				samples.at<float>(n_sample,0) = train_data[k][1]; //
				samples.at<float>(n_sample,1) = train_data[k][2];
				samples.at<float>(n_sample,2) = train_data[k][3];
				samples.at<float>(n_sample,3) = train_data[k][4];
				samples.at<float>(n_sample,4) = train_data[k][5];

				output.at<float>(n_sample,0) = (o[k] == 1) ? 1 : -1;
				if (o[k] == 1) occs++; else non_occs++;

				X(n_sample,0) = train_data[k][1];
				X(n_sample,1) = train_data[k][2];
				X(n_sample,2) = train_data[k][3];
				X(n_sample,3) = train_data[k][4];
				X(n_sample,4) = train_data[k][5];
				X(n_sample,5) = 1;
				y(n_sample) = (o[k] == 1) ? 1 : -1;

				n_sample++;
			}
		}
		//math::algebra::LeastSquaresRegression regr; //<math::numeric::L1Robust>
		//regr.fit(X,y);
		//math::Vector a = regr.solution();

		//std::cout << "weight " << a.transpose() << std::endl;
		// train
		std::cout << "Training " << i << " with " << n_sample << " classes " << occs/(occs+non_occs) << " " << non_occs/(occs+non_occs) << std::endl;

		std::string classifier_name = "boost";

		/*float priors[] = {1,1};  // weights of each classification for classes
		CvRTParams params = CvRTParams(25, // max depth
		                                       5, // min sample count
		                                       0, // regression accuracy: N/A here
		                                       false, // compute surrogate split, no missing data
		                                       15, // max number of categories (use sub-optimal algorithm for larger numbers)
		                                       priors, // the array of priors
		                                       true,  // calculate variable importance
		                                       4,       // number of variables randomly selected at node and used to find the best split(s).
		                                       100,	 // max number of trees in the forest
		                                       0.01f,				// forrest accuracy
		                                       CV_TERMCRIT_ITER |	CV_TERMCRIT_EPS // termination cirteria
		                                      );
		CvRTrees classifier;
		classifier.train(samples, CV_ROW_SAMPLE, output, cv::Mat(), cv::Mat(), cv::Mat(), cv::Mat(), params);*/

		/*CvSVMParams params 	= CvSVMParams () ;
		params.svm_type 		= CvSVM::C_SVC ;
		params.kernel_type 		= CvSVM::LINEAR ;
		params.term_crit.type 		= CV_TERMCRIT_EPS ;
		params.term_crit.epsilon 	= 1e-6;
		params.C					= 0.1;
		CvSVM classifier;*/

		float priors[] = {1,1};  // weights of each classification for classes
		CvBoostParams params(CvBoost::REAL, 100, 0.95, 1, true, priors);
		CvBoost classifier;
		classifier.train(samples, CV_ROW_SAMPLE, output, cv::Mat(), cv::Mat(), cv::Mat(), cv::Mat(), params);


		//CvNormalBayesClassifier classifier;
		//classifier.train(samples,output);

		//classifier.train(samples, output, cv::Mat(), cv::Mat(), params);
		//classifier.train(samples, CV_ROW_SAMPLE, output, cv::Mat(), cv::Mat(), cv::Mat(), cv::Mat(), params);

		//std::cout << "weight vector " << classifier.getVarImportance() << std::endl;

		// test
		std::cout << "Testing " << i << std::endl;
		for (std::set<uint64>::iterator t = test[i].begin(); t != test[i].end(); t++) {
			std::cout << "Testing seq " << *t << std::endl;
			std::ostringstream os;
			std::string seq_path;
			os << path << "/" << *t; seq_path = os.str(); os.str("");
			uint64 sx = photo[*t].size_x();
			uint64 sy = photo[*t].size_y();

			//int k = 0;
			ConfidenceMapType map(sx,sy);
			for (ConfidenceMapType::iterator p = photo[*t].begin(); p != photo[*t].end(); ++p) {
				ConfidenceMapType::coord_type pos = p.pos();

				/*math::Vector s(D+1);
				s(0) = photo[*t](pos)(0);
				s(1) = var[*t](pos)(0);
				s(2) = ep[*t](pos)(0);
				s(3) = epa[*t](pos)(0);
				s(4) = bij[*t](pos)(0);
				s(5) = 1;
				float64 v = s.transpose() * a;
				if (v < -1) v = -1;
				if (v > 1) v = 1;
				map(pos)(0) = 0.5 + 0.5*v;*/
				test_sample.at<float>(0,0) = photo[*t](pos)(0);
				test_sample.at<float>(0,1) = var[*t](pos)(0);
				test_sample.at<float>(0,2) = ep[*t](pos)(0);
				test_sample.at<float>(0,3) = epa[*t](pos)(0);
				test_sample.at<float>(0,4) = bij[*t](pos)(0);
				map(pos)(0) = 0.5+0.5*classifier.predict(test_sample, missing);
				//map(pos)(0) = classifier.predict_prob(test_sample);//, missing);
				//k++;
			}

			os << seq_path << "/occ_" << classifier_name << ".txt"; precision_recall(map,occ_gt[*t],Nth,os.str()); os.str("");
			ImageSignal<float64,3> map_img = convert_map_to_image(map);
			os << seq_path << "/" << classifier_name << ".png"; map_img.write(os.str()); os.str("");
		}
	}

}
