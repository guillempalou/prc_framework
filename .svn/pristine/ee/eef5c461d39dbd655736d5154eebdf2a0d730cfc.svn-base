/*
 * video_relative_depth.cpp
 *
 *  Created on: Dec 17, 2012
 *      Author: gpalou
 */

#include <imageplus/core/image_signal.hpp>
#include <imageplus/core/video_signal.hpp>
#include <imageplus/core/colorspace_converter.hpp>

#include <imageplus/segmentation/partition/partition.hpp>
#include <imageplus/segmentation/partition/hierarchical_region_partition.hpp>
#include <imageplus/segmentation/visualization/false_color.hpp>

#include <imageplus/math/graphs/graph.hpp>

#include <imageplus/optical_flow/flow_io.hpp>
#include <imageplus/optical_flow/trajectory_tracking.hpp>
#include <imageplus/optical_flow/occlusions/boundary_owner.hpp>
#include <imageplus/optical_flow/occlusions/bijective_error.hpp>
#include <imageplus/optical_flow/occlusions/region_occlusion_error.hpp>
#include <imageplus/optical_flow/occlusions/detect_occlusion_relations.hpp>

#include <imageplus/bpt/energy_minimization/binary_pruner.hpp>
#include <imageplus/bpt/pruning/merging_sequence_pruner.hpp>
#include <imageplus/bpt/pruning/min_area_pruner.hpp>

#include <imageplus/video_segmentation/trajectory_bpt/trajectory.hpp>
#include <imageplus/video_segmentation/trajectory_bpt/motion_color_distance.hpp>
#include <imageplus/video_segmentation/optical_flow_fitting/occlusion_cost.hpp>
#include <imageplus/video_segmentation/optical_flow_fitting/bidirectional_projective_cost.hpp>
#include <imageplus/video_segmentation/optical_flow_fitting/bidirectional_affine_cost.hpp>
#include <imageplus/video_segmentation/optical_flow_fitting/model_optical_flow.hpp>

#include <imageplus/monocular_depth/conflict_resolution/join_components_and_order.hpp>
#include <imageplus/monocular_depth/conflict_resolution/resolve_depth_conflicts.hpp>

#include <boost/filesystem.hpp>
#include <iomanip>
#include <iostream>

using namespace imageplus;

#define uint64 imageplus::uint64
#define int64 imageplus::int64

typedef VideoSignal<float64,3> 																		VideoType;
typedef VideoSignal<float64,2>																		OpticalFlowType;
typedef VideoSignal<uint64,1>																		PartitionIndexType;
typedef VideoSignal<float64,1>																		ConfidenceMapType;

typedef VideoType::ImageType																		FrameType;
typedef OpticalFlowType::ImageType																	OpticalFlowFrame;
typedef PartitionIndexType::ImageType																PartitionIndexFrame;
typedef ConfidenceMapType::ImageType																ConfidenceMapFrame;

typedef FrameType::coord_type																		coord2d;
typedef VideoType::coord_type																		coord3d;
typedef VideoType::value_type																		rgb_type;

typedef HierarchicalRegion<coord3d>																	Region3D;
typedef video_segmentation::Trajectory<VideoType>													TrajectoryType;
typedef segmentation::HierarchicalRegionPartition<TrajectoryType>									BPT;
typedef BPT::PartitionType																			PartitionType;

typedef math::graphs::BoostGraph<math::graphs::kGraphBidirectional, math::graphs::NodeMaxFlowProperties, math::graphs::EdgeMaxFlowProperties>  DOG;

//typedef MeanColorDistanceModel<VideoType, TrajectoryType>	 DistanceModelType;
typedef video_segmentation::MotionColorDistanceModel<VideoType, TrajectoryType, OpticalFlowType> 	DistanceModelType;

FrameType convert_map_to_image(ConfidenceMapFrame& s) {
	typedef ConfidenceMapFrame::coord_type 	coord2d;
	FrameType res(s.sizes());
	for (ConfidenceMapFrame::iterator p = s.begin(); p!=s.end(); ++p) {
		coord2d pos = p.pos();
		float64 value = (*p)(0); if (value < 0) value=0;
		res(pos) = value*rgb_type(255,255,255);
	}
	return res;
}

int main(int argc, char *argv[]) {
	std::istringstream sstart(argv[1]);
	std::istringstream send(argv[2]);

	std::istringstream swindow(argv[3]);

	std::string path 		= argv[4];
	std::string segm_path 	= argv[5];
	std::string result_path = argv[6];

	uint64 start = 0; sstart >> start;
	uint64 end = -1; send >> end;
	int64 window = 0; swindow >> window;

	std::string video_path = path + "/frames";
	std::string flows_path = path + "/flows";
	std::string partition_path = segm_path + "/leaves.sgm";
	std::string mergings_path  = segm_path + "/mergings.txt";

	// create the necessary paths
	boost::filesystem::path result_path_p(result_path);

	boost::filesystem::create_directory(result_path_p);
	boost::filesystem::create_directory(result_path_p / "modeled_flows");
	boost::filesystem::create_directory(result_path_p / "occlusions");
	boost::filesystem::create_directory(result_path_p / "occlusion_relations");
	boost::filesystem::create_directory(result_path_p / "depths");
	boost::filesystem::create_directory(result_path_p / "fg");

	std::cout << "Reading tree" << std::endl;
	BPT bpt;
	bpt.load_from_files(partition_path, mergings_path);
	coord3d sizes = bpt.leaves_partition().sizes();

	uint64 Nframes = sizes(2);

	VideoType video(sizes);
	OpticalFlowType forward_flows(sizes);
	OpticalFlowType backward_flows(sizes);

	std::cout << "Reading video with " << Nframes << " frames " << std::endl;
	for (uint64 k = start; k <= end; k++) {
		std::ostringstream os;
		os << video_path << "/frame" << std::setw(3) << std::setfill('0') << k << ".png";
		//std::cout << "reading " << os.str() << std::endl;
		video.read_frame(os.str(),k-start); // read frame k and put it to the position k of the current block
	}

	ColorSpaceConverter<VideoType> converter;
	converter.convert(video, ColorSpaceLAB);

	// Read forward optical flows
	std::cout << "Reading forward flow" << std::endl;
	for (uint64 k = start; k <= end-1; k++) {
		std::ostringstream os;
		os << flows_path << "/flow_" << k << "_" << k+1 << ".flo";
		OpticalFlowFrame flow = forward_flows.frame(k-start);
		optical_flow::read_optical_flow(flow, os.str());  // read flow k,k+1 and put it to the position k of the current block
	}

	// Read backward optical flows
	std::cout << "Reading backward flow" << std::endl;
	for (uint64 k = start+1; k <= end; k++) {
		std::ostringstream os;
		os << flows_path << "/flow_" << k << "_" << k-1 << ".flo";
		OpticalFlowFrame flow = backward_flows.frame(k-start);
		optical_flow::read_optical_flow(flow, os.str()); // read flow k,k-1 and put it to the position k of the current block
	}

	//bpt::MinAreaPruner<BPT, VideoType> min_area_pruner(0.005*video.sizes().prod(),true);
	//min_area_pruner.prune_bpt(bpt,video);

	std::cout << "Oversegmentation done, estimating flow models" << std::endl;

	descriptors::DescriptorManager manager;
	// estimate flow models (too costly)
	typedef bpt::BidirectionalProjectiveCost<BPT,OpticalFlowType> 				OpticalFlowCostFunction;
	typedef bpt::BinaryPruner<BPT,OpticalFlowType,OpticalFlowCostFunction>		FlowPruner;

	//descriptors::DescriptorManager manager;
	OpticalFlowCostFunction projective_flow_cost(manager, bpt.max_label(), 4000*Nframes);
	FlowPruner optical_flow_pruner(projective_flow_cost,false);

	projective_flow_cost.set_flows(forward_flows, backward_flows);
	optical_flow_pruner.prune_bpt(bpt,forward_flows);

	//std::set<uint64> regs = min_area_pruner.regions(); //
	std::set<uint64> regs = optical_flow_pruner.regions();
	std::cout << "Prune with " << regs.size() << " regions " << std::endl;

	//print modeled optical flows
	std::cout << "Printing modeled flows" << std::endl;
	OpticalFlowType fwd_modeled(forward_flows.sizes());
	OpticalFlowType bwd_modeled(backward_flows.sizes());

	for (std::set<uint64>::iterator r = regs.begin(); r != regs.end(); ++r) {
		for (int64 frame = bpt(*r).frame_begin(); frame <= bpt(*r).frame_end(); ++frame) {
			OpticalFlowFrame fwd 				= forward_flows.frame(frame);
			OpticalFlowFrame bwd 				= backward_flows.frame(frame);
			OpticalFlowFrame fwd_model_frame 	= fwd_modeled.frame(frame);
			OpticalFlowFrame bwd_model_frame 	= bwd_modeled.frame(frame);

			video_segmentation::projective_flow_model(bpt, fwd, fwd_model_frame,frame, *r);
			video_segmentation::projective_flow_model(bpt, bwd, bwd_model_frame,frame, *r);
		}
	}

	for (uint64 k = 0; k < Nframes-1; k++) {
		std::ostringstream os;
		os << result_path << "/modeled_flows/fwd_" << k+start << "_" << k+start+1 << ".png";
		OpticalFlowFrame flow = fwd_modeled.frame(k);
		optical_flow::write_flow_image(flow, os.str());  // read flow k,k+1 and put it to the position k of the current block
	}
	for (uint64 k = 1; k < Nframes; k++) {
		std::ostringstream os;
		os << result_path << "/modeled_flows/fwd_" << k+start << "_" << k+start-1 << ".png";
		OpticalFlowFrame flow = bwd_modeled.frame(k);
		optical_flow::write_flow_image(flow, os.str()); // read flow k,k-1 and put it to the position k of the current block
	}

	//estimate occlusions (optimum threshold at 0.366)
	float64 optimum_th = 0.366;
	ConfidenceMapType occlusions(video.sizes());
	ConfidenceMapType disocclusions(video.sizes());

	/*std::cout << "Computing occlusions " << std::endl;
	for (uint64 k = 0; k < Nframes-1; k++) {
		FrameType 				img1 	= video.frame(k);
		FrameType 				img2 	= video.frame(k+1);
		ConfidenceMapFrame 		occ    	= occlusions.frame(k);
		OpticalFlowFrame 		fwd		= forward_flows.frame(k);

		ConfidenceMapFrame bij = optical_flow::bijective_error(img1,img2,fwd);
		occ.channel(0) = bij.channel(0);
	}

	std::cout << "Computing disocclusions " << std::endl;
	for (uint64 k = 1; k < Nframes; k++) {
		FrameType 				img1 	= video.frame(k);
		FrameType 				img2 	= video.frame(k-1);
		ConfidenceMapFrame 		disocc 	= disocclusions.frame(k);
		OpticalFlowFrame 		bkd 	= backward_flows.frame(k);

		ConfidenceMapFrame bij = optical_flow::bijective_error(img1,img2,bkd);
		disocc.channel(0) = bij.channel(0);
	}*/

	// Computing Regon-Based Occlusions
	PartitionType partition_flow(video.sizes());
	for (std::set<uint64>::iterator r = regs.begin(); r != regs.end(); ++r) {
		for (BPT::RegionType::iterator p = bpt(*r).begin(); p != bpt(*r).end(); ++p) {
			partition_flow(*p)(0) = *r;
		}
	}

	std::cout << "Computing region based occlusions" << std::endl;
	for (uint64 k = 0; k < Nframes-1; k++) {
		ConfidenceMapFrame 		occ    	= occlusions.frame(k);
		OpticalFlowFrame 		fwd		= fwd_modeled.frame(k);
		OpticalFlowFrame 		bwd		= backward_flows.frame(k+1);

		ConfidenceMapFrame bij = optical_flow::region_occlusion_error(partition_flow, fwd, bwd, k);
		occ.channel(0) = bij.channel(0);
	}

	std::cout << "Computing region based disocclusions " << std::endl;
	for (uint64 k = 1; k < Nframes; k++) {
		ConfidenceMapFrame 		disocc 	= disocclusions.frame(k);
		OpticalFlowFrame 		bkd 	= bwd_modeled.frame(k);
		OpticalFlowFrame 		fwd		= forward_flows.frame(k-1);

		ConfidenceMapFrame bij = optical_flow::region_occlusion_error(partition_flow, bkd, fwd, k);
		disocc.channel(0) = bij.channel(0);
	}

	ConfidenceMapType::iterator p = occlusions.begin();
	ConfidenceMapType::iterator p_end = occlusions.end();
	for (;p!=p_end; ++p) {
		occlusions(p.pos())(0) = (occlusions(p.pos())(0) > optimum_th) ? 1 : 0;
		disocclusions(p.pos())(0) = (disocclusions(p.pos())(0) > optimum_th) ? 1 : 0;
	}

	std::cout << "Output occlusion maps" << std::endl;
	// Write occlusion map
	for (uint64 k = 0; k < Nframes; k++) {
		ConfidenceMapFrame of = occlusions.frame(k);
		ConfidenceMapFrame dof = disocclusions.frame(k);
		FrameType o    = convert_map_to_image(of);
		FrameType diso = convert_map_to_image(dof);

		std::ostringstream os;
		os << result_path << "/occlusions/occ_" << std::setw(3) << std::setfill('0') << k+start << ".png";
		o.write(os.str()); os.str("");

		os << result_path << "/occlusions/disocc_" << std::setw(3) << std::setfill('0') << k+start << ".png";
		diso.write(os.str());
	}

	std::cout << "Estimating occlusion relations" << std::endl;

	std::vector<std::pair<coord3d,coord3d> > relations;

	int64 center = (Nframes-1)/2;
	for (int64 k = 0; k < (int64)Nframes; k++) {

		if (!((k > center-window) && (k < center+window))) continue;

		ConfidenceMapFrame of = occlusions.frame(k);
		ConfidenceMapFrame dof = disocclusions.frame(k);

		OpticalFlowFrame fwd_frame_modeled = fwd_modeled.frame(k);
		OpticalFlowFrame bwd_frame_modeled = bwd_modeled.frame(k);

		// Detect disocclusions
		if (k > 0) {
			OpticalFlowFrame fwd_previous = fwd_modeled.frame(k-1);
			std::vector<std::pair<coord2d,coord2d> > v = optical_flow::detect_occlusion_relations(dof,bwd_frame_modeled,fwd_previous);
			for (uint64 i = 0; i < v.size(); i++) {
				coord3d a = coord3d(v[i].first(0),v[i].first(1),k);
				coord3d b = coord3d(v[i].second(0),v[i].second(1),k);
				if (disocclusions(b)(0) > 0) continue;
				relations.push_back(std::pair<coord3d,coord3d>(a,b));
			}
		}

		// Detect occlusions
		if (k < (int64)Nframes-1) {
			OpticalFlowFrame bwd_next = bwd_modeled.frame(k+1);
			std::vector<std::pair<coord2d,coord2d> > v = optical_flow::detect_occlusion_relations(of,fwd_frame_modeled, bwd_next);
			for (uint64 i = 0; i < v.size(); i++) {
				coord3d a = coord3d(v[i].first(0),v[i].first(1),k);
				coord3d b = coord3d(v[i].second(0),v[i].second(1),k);
				if (occlusions(b)(0) > 0) continue;
				relations.push_back(std::pair<coord3d,coord3d>(a,b));
			}
		}
	}

	//Second pruning according to depth
	typedef bpt::OcclusionCost<BPT,VideoType> 							OcclusionCostFunction;
	typedef bpt::BinaryPruner<BPT,VideoType,OcclusionCostFunction>		OcclusionPruner;

	for (int64 cas = 7; cas <= argc; cas++) {
		float64 regularizer = atof(argv[cas]);
		std::cout << "Doing with regularizer " << regularizer << std::endl;

		OcclusionCostFunction occlusion_cost(manager, bpt.max_label(),0.005*regularizer);
		OcclusionPruner occlusion_pruner(occlusion_cost,false);

		occlusion_cost.set_occlusion_relations(relations);
		occlusion_pruner.prune_bpt(bpt,video);

		regs = occlusion_pruner.regions();

		PartitionType& leaves = bpt.leaves_partition();

		DOG dog;
		std::map<uint64, DOG::Node> nodes;
		for (std::set<uint64>::iterator r = regs.begin(); r !=regs.end(); ++r) {
			DOG::Node n = dog.add_node();
			dog.node_properties(n).id = *r;
			nodes[*r] = n;
			for (BPT::RegionType::iterator p = bpt(*r).begin(); p != bpt(*r).end(); ++p) {
				leaves(*p)(0) = *r;
			}
		}

		PartitionIndexType partition(leaves.sizes());
		for (PartitionIndexType::iterator x = partition.begin(); x != partition.end(); ++x) {
			(*x)(0) = leaves(x.pos())(0);
		}

		VideoType occ_relations_video(video.sizes());
		for (uint64 i = 0; i < relations.size(); i++) {
			if (leaves(relations[i].first)(0) == leaves(relations[i].second)(0)) continue;

			FrameType occ_relations = occ_relations_video.frame(relations[i].first(2));
			occ_relations(relations[i].first(0),relations[i].first(1)) = rgb_type(0,0,255);
			occ_relations(relations[i].second(0), relations[i].second(1)) = rgb_type(0,255,0);
		}

		for (int64 k = 0; k < (int64)Nframes; k++) {
			if (!((k > center-window) && (k < center+window))) continue;
			FrameType			occ_relations = occ_relations_video.frame(k);
			std::ostringstream os;
			os << result_path << "/occlusion_relations/relations_" << std::setw(3) << std::setfill('0') << k+start << ".png";
			occ_relations.write(os.str()); os.str("");
		}

		std::cout << "Putting occlusion relations " << std::endl;
		uint64 N = relations.size();
		float64 max_conf = 0;
		for (uint64 i = 0; i < N; i++) {
			coord3d a = relations[i].first;
			coord3d b = relations[i].second;
			uint64 ra = leaves(a)(0);
			uint64 rb = leaves(b)(0);
			if (ra == rb) continue;
			DOG::Node na = nodes[ra];
			DOG::Node nb = nodes[rb];
			if (!dog.edge_exists(nb,na)) {
				DOG::Edge e = dog.add_edge(nb,na);
				dog.edge_properties(e).weight = 1.0/N;
				dog.edge_properties(e).capacity = 1.0/N;
				if (max_conf < 1.0/N) max_conf = 1.0/N;
			} else {
				DOG::Edge e = dog.edge(nb,na);
				dog.edge_properties(e).weight += 1.0/N;
				dog.edge_properties(e).capacity += 1.0/N;
				if (max_conf < 1.0/N) max_conf = dog.edge_properties(e).capacity;
			}
		}



		// Depth order by depth
		monocular_depth::resolve_depth_conflicts(dog);

		// join disconnected connected according to the distance in the BPT components to enforce consistency

		optical_flow::TrajectoryTracking<VideoType, OpticalFlowType, PartitionType>::Parameters tracker_pars;
		tracker_pars.occlusion_lambda = 1;
		tracker_pars.variation_lambda = 1;
		tracker_pars.structure_lambda = 2;
		optical_flow::TrajectoryTracking<VideoType, OpticalFlowType, PartitionType> tracker(video, tracker_pars);
		tracker.calculate(video,forward_flows, backward_flows);

		//Parameters are not very critical, using 14,4,0.05 for color,motion,area respectively
		DistanceModelType::Parameters model_pars;
		model_pars.optical_flow = forward_flows;
		model_pars.color_damping = (1.0/(14*14));
		model_pars.motion_damping = 1.0/(4*4);
		model_pars.area_damping = 1.0 / (video.sizes().prod() * 0.1);
		model_pars.num_colors = 8;
		model_pars.flow_reliability = tracker.flow_reliability();

		DistanceModelType distance_model(model_pars);
		std::map<uint64,std::pair<float64,uint64> > depths =  monocular_depth::join_components_and_order(dog, bpt, video, distance_model);

		// output the depth ordering
		float64 max_d = 0;
		float64 min_d = 1e9;
		for (std::map<uint64,std::pair<float64,uint64> >::iterator d = depths.begin(); d != depths.end(); ++d) {
			if (max_d < d->second.first) max_d = d->second.first;
			if (min_d > d->second.first) min_d = d->second.first;
		}

		float64 dif = max_d - min_d; if (dif == 0) dif = 1;
		VideoType depth(video.sizes());
		for (std::map<uint64,std::pair<float64,uint64> >::iterator d = depths.begin(); d != depths.end(); ++d) {
			uint64 r = d->first;
			float64 rd = d->second.first;
			float64 component = d->second.second;
			rgb_type depth_color = rgb_type::Ones() * 255 * (max_d - rd) / dif;
			for (BPT::RegionType::iterator p = bpt(r).begin(); p != bpt(r).end(); ++p) {
				bool border = false;

				typedef PartitionType::general_adjacency_iterator<neighborhood_traits<3>::default_forward_connectivity>::type  adj_iterator;
				adj_iterator adj		 	=  bpt.leaves_partition().general_adjacency_begin<neighborhood_traits<3>::default_forward_connectivity>(*p);
				adj_iterator adj_end 		=  bpt.leaves_partition().general_adjacency_end<neighborhood_traits<3>::default_forward_connectivity>(*p);

				for (;adj!=adj_end;++adj) {
					if (adj.pos()(2) != (*p)(2)) continue;
					uint64 comp_adj = depths[bpt.leaves_partition()(adj.pos())(0)].second;
					if (comp_adj != component) border = true;
				}

				//if (border)
				//	depth(*p) = rgb_type(0,0,255);
				//else
					depth(*p) = depth_color;
			}
		}
		std::ostringstream os;
		os << result_path << "/depths/" << cas-7;

		boost::filesystem::create_directory(os.str());

		for (uint64 k = 0; k < Nframes; k++) {
			std::ostringstream os;
			os << result_path << "/depths/" << cas-7 << "/depth_" << std::setw(3) << std::setfill('0') << k+start << ".png";

			FrameType depth_frame = depth.frame(k);
			depth_frame.write(os.str());  // read flow k,k+1 and put it to the position k of the current block
		}
	} // of regularizers

}

	/*float64 sigma = 30;
		float64 th = 0.1;
		for (DOG::edge_iterator e = dog.edges_begin(); e != dog.edges_end(); ++e) {
			float64 w = dog.edge_properties(*e).weight;
			float64 v = 1 - std::exp(-w/sigma);
			if (w < th) {
				v = 0;
			}
			std::cout << "Edge " << v << std::endl;
			dog.edge_properties(*e).weight 	= v;
			dog.edge_properties(*e).capacity = v;
		}*/


		//estimate boundary owners at each frame

		/*std::map<uint64, std::map<uint64, float64> > owners;
		for (int64 k = 0; k < (int64)Nframes; k++) {

			if (!((k > center-window) && (k < center+window))) continue;

			PartitionIndexFrame partition_frame = partition.frame(k);
			//std::cout << "Mask " << std::endl;
			ConfidenceMapFrame mask = optical_flow::construct_mask<ConfidenceMapFrame>(partition_frame,(uint64)2);
			std::map<uint64, std::map<uint64, float64> > owners_forward;
			std::map<uint64, std::map<uint64, float64> > owners_backward;
			//std::cout << "Owners forward" << std::endl;
			if (k < (int64)Nframes -1) {
				OpticalFlowFrame	forward_flow_frame = forward_flows.frame(k);
				owners_forward = optical_flow::boundary_owners(partition_frame, mask, forward_flow_frame);
			}
			//std::cout << "Owners backward" << std::endl;
			if (k > 0) {
				OpticalFlowFrame	backward_flow_frame = backward_flows.frame(k);
				owners_backward = optical_flow::boundary_owners(partition_frame, mask, backward_flow_frame);
			}

			for (std::map<uint64,DOG::Node>::iterator r1 = nodes.begin(); r1 != nodes.end(); ++r1) {
				for (std::map<uint64,DOG::Node>::iterator r2 = nodes.begin(); r2 != nodes.end(); ++r2) {
					owners[r1->first][r2->first] += owners_forward[r1->first][r2->first] + owners_backward[r1->first][r2->first];
				}
			}
		}

		for (std::map<uint64,DOG::Node>::iterator r1 = nodes.begin(); r1 != nodes.end(); ++r1) {
			for (std::map<uint64,DOG::Node>::iterator r2 = nodes.begin(); r2 != nodes.end(); ++r2) {

				uint64 reg1 = r1->first;
				uint64 reg2 = r2->first;
				DOG::Node n1 = nodes[reg1];
				DOG::Node n2 = nodes[reg2];

				if (owners[reg1][reg2] != 0 || owners[reg2][reg1] != 0) {
					float64 N12 = owners[reg1][reg2];
					float64 N21 = owners[reg2][reg1];

					if (N12 <= N21) continue;


					float64 conf = 2*(N12/(N12 + N21) - 0.5);
					if (conf < 0.1) continue;

					DOG::Edge e = dog.add_edge(n1,n2);
					dog.edge_properties(e).weight = conf;
					dog.edge_properties(e).capacity = conf;
					//std::cout << "Adding " << n1 << " " << n2 << " (" << reg1 << "," << reg2 << ") " << conf << std::endl;
				}
			}
		}*/
