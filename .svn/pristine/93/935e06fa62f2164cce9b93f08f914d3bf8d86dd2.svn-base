//!
//!  \file pca.hpp
//!
//!  Class with the methods to compute the Principal Component Analisis (PCA)
//!
//!
//!

#ifndef IMAGEPLUS_MATH_TRANSFORMS_PCA_HPP
#define IMAGEPLUS_MATH_TRANSFORMS_PCA_HPP

#include <imageplus/core.hpp>
#include <string>

namespace imageplus
{
    namespace math
    {
        namespace transforms
        {
            //!
            //! \brief Class to implement PCA algorithm
            //! 
            //! Principal component analysis (PCA) involves a mathematical procedure that transforms a 
            //! number of possibly correlated variables into a smaller number of uncorrelated variables 
            //! called principal components. 
            //! http://en.wikipedia.org/wiki/Principal_component_analysis\n
            //! PCA is mathematically defined as an orthogonal linear transformation that transforms the data 
            //! to a new coordinate system such that the greatest variance by any projection of the data comes 
            //! to lie on the first coordinate (called the first principal component), the second greatest 
            //! variance on the second coordinate, and so on. PCA is theoretically the optimum transform for 
            //! given data in least square terms. Depending on the field of application, it is 
            //! also named the discrete Karhunen–Loève transform (KLT), the Hotelling transform or proper 
            //! orthogonal decomposition (POD).\n
            //! PCA involves the calculation of the eigenvalue decomposition of a data covariance matrix, 
            //! after mean centering the data for each attribute.\n
            //! This class computes the PCA analysis for a set of input data items or observations.
            //! Input data are given as a set of column vectors, forming a 2D multiarray. To work with images, 
            //! they must be first converted to column vectors:\n
            //! i i i i\n
            //! m m m m\n
            //! a a a a\n
            //! g g g g\n
            //! e e e e\n
            //! 1 2 3 4\n
            //! The operation is as follows: with a set of observations (training data, consisting of vectors or images 
            //! of some type, describing a process), a 2D matrix describing the linear transformation is computed.
            //! This matrix describes the basis of the new coordinate system and has the same dimensionality as 
            //! the training set. For dimensionality reduction, the last basis vectors of the transformation
            //! are discarded (they tend to be highly correlated and may be dropped with minimal loss of information)
            //! The resulting matrix can be used to 'project' new data vectors (not belonging to the training data)
            //! into the lower dimensionality subspace. 
            //!
            //! Implementation details:\n\n
            //! The implementation of this class work as follows: \n
            //! 1. The input (constructor) is a set of training vectors. If the samples are images, they must be resampled to the same
            //!    pixel resulution (same dimensions) and represented as a vector, concatenating its rows, resulting in a single column 
            //!    row with r × c elements. For this implementation, it is assumed that all images of the training set are stored in a 
            //!    single matrix T, where each column of the matrix is an sample vector.\n
            //! 2. The mean of the images is substracted. The average image a has to be calculated and then subtracted from each original image in T.\n
            //! 3. While PCA usually computes the eigenvectors and eigenvalues of the covariance matrix S = TT^T, \n
            //!    \f$ \mathbf{Sv}_i = \mathbf{T^T}\mathbf{Tv}_i = \lambda_i \mathbf{v}_i \f$ \n
            //!    and use a subset of the resulting eigenvalues as a projection basis, this process can be computationally infeasible 
            //!    if the dimension of the sample vectors are high. If the number of training examples is smaller than the dimensionality 
            //!    of the images, an alternative approach can be used, consisting of computing the 
            //!    eigenvalue descomposition of \f$ \mathbf{TT^T}\mathbf{u}_i = \lambda_i \mathbf{u}_i \f$ and obtaining
            //!    the non-null eigenvectors of S (S has a rank limited by the number of training examples: if there are N training 
            //!    examples, there will be at most N-1 eigenvectors with non-zero eigenvalues) as:\n
            //!    \f$ v_i=Tu_i \f$ 
            //!    and applying an extra normalization step.\n
            //! 4. The resulting matrix containing the eigenvectors v_i (or a subset of these vectors) is the matrix that will be used
            //!    to project vectors in the resulting subspace.
            //!
            //! \author Roger Gimeno Hernandez <algimeno@gps.tsc.upc.edu>
            //! \author Josep Ramon Morros  <ramon.morros@upc.edu>
            //!
            //! \date 03-06-2008
            //!

            template <typename T, typename T2>
            class PCA
            {
                public:

                    //!
                    //! \brief Default constructor
                    //!
                    PCA ( ); 


                    //!
                    //! \brief Initialize all the variables with the input matrix
                    //!
                    //! \param[in] image: 2D, real (non-complex) matrix
                    //! \param[in] dim_x: dim x of the used images
                    //! \param[in] dim_y: dim y of the used images
                    //!
                    PCA (const MultiArray<T2,2>& image, uint64 dim_x, uint64 dim_y); 


                    //!
                    //! \brief Initialize all the variables with the information of a file
                    //!
                    //! \param[in] classn: File name
                    //!
                    PCA (std::string classn);

                    
                    //!
                    //! \brief Fill all the variables with the information of a file
                    //!
                    //! \param[in] classn: file with information
                    //!
                    void load (std::string classn) ;
                    
                    
                    //!
                    //! \brief Return the horizontal size of the matrix
                    //!
                    //! \return  Horizontal size of the matrix
                    //!
                    uint64 size_x() const;


                    //!
                    //! \brief Return the vertical size of the matrix
                    //!
                    //! \return Vertical size of the matrix
                    //!
                    uint64 size_y() const;


                    //!
                    //! \brief Return the number of selected eigenvectors of the matrix
                    //!
                    //! \return Number of selected eigenvectors
                    //!
                    uint64 selected_eigenvectors() const;


                    //!
                    //! \brief Return the number of eigenvalues (as many as input images)
                    //!
                    //! \return Number of eigenvalues
                    //!
                    uint64 total_number_eigenvalues() const;


                    //!
                    //! \brief Return discarded eigenvalues mean
                    //!
                    //! \return Discarded eigenvalues mean
                    //!
                    float64 discarded_eigenvalues_mean() const;


                    //!
                    //! \brief Return the mean of the image matrix
                    //!
                    //! \return Mean of the input images
                    //!
                    MultiArray<T,1> mean_image() const;


                    //!
                    //! \brief Return the eigenvalues matrix
                    //!
                    //! \return vector with eigenvalues from higher to smaller
                    //!
                    MultiArray<T,1> eigenvalues() const;


                    //!
                    //! \brief Return the PCA projection basis matrix
                    //!
                    //! \return PCA projection basis matrix
                    //!
                    MultiArray<T,2> projection_basis() const;


                    //!
                    //! \brief Keeps only the M first eigenvectors and eigenvalues and discards the rest.
                    //!
                    //! \param[in] num_sel: Number of selected eigenvalues
                    //!
                    void reduce_class (uint64 num_sel);


                    //!
                    //! \brief Saves the class on disk
                    //!
                    //! \param[in] classn: Name of the file where you want to save the PCA class
                    //!
                    void save(std::string classn) const;


                    //!
                    //! \brief Computes feature vector of input row-wise image
                    //!
                    //! \param[in] image: 1D-MultiArray (row-wise image)
                    //!
                    //! \return 1D MultiArray (feature vector)
                    //!
                    MultiArray<T,1> projection(const MultiArray<T,1>& image) const;


                    //!
                    //! \brief Computes feature vectors of input row-wise images
                    //!
                    //! \param[in] images: 2D MultiArray (one row-wise image per row)
                    //!
                    //! \return 2D MultiArray (one feature vector per row)
                    //!
                    MultiArray<T,2> projection(const MultiArray<T,2>& images) const;


                private:
                    //!
                    //! \brief Integer for internal storage of horitzontal dimension.
                    //!
                    uint64 _x;


                    //!
                    //! \brief Integer for internal storage of vertical dimension.
                    //!
                    uint64 _y;


                    //!
                    //! \brief Integer for internal storage of # of selected eigenvectors
                    //!
                    uint64 _sel_evec;


                    //!
                    //! \brief Integer for internal storage of # eigenvalues.
                    //!
                    uint64 _number_eval;


                    //!
                    //! \brief float for internal storage of discarded eigenvalues mean.
                    //!
                    float64 _discarded_eval_mean;


                    //!
                    //! \brief Array for internal storage of image mean.
                    //!
                    MultiArray<T,1> _mean_im;


                    //!
                    //! \brief Array for internal storage of eigenvalues.
                    //!
                    MultiArray<T,1> _eval;


                    //!
                    //! \brief Array for internal storage of eigenvectors.
                    //!
                    MultiArray<T,2> _basis;


                    //!
                    //! \brief Compute PCA algorithm
                    //!
                    //! \param[in] xmat: Image to use
                    //!
                    void _compute_pca (const MultiArray<T2,2>& xmat);


                    //!
                    //! \brief Re-ordenate matrices with the most weight coeficients at the beginning
                    //!
                    //! \param[in] eigenvalues: eigenvalues
                    //! \param[in] _basis: projection basis
                    //!
                    void _sortevv(MultiArray<T,1>& eigenvalues, MultiArray<T,2>& _basis);
            };
        }
    }
}

#endif
