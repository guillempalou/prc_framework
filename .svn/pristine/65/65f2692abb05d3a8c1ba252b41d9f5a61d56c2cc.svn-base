// --------------------------------------------------------------
// Copyright (C)
// Universitat Politecnica de Catalunya (UPC) - Barcelona - Spain
// --------------------------------------------------------------

//!
//!  \file probability_density_function.hpp
//!

#ifndef IMAGEPLUS_MATH_STATISTICS_PROBABILITY_DENSITY_FUNCTION_HPP
#define IMAGEPLUS_MATH_STATISTICS_PROBABILITY_DENSITY_FUNCTION_HPP

#include <imageplus/core/visual_descriptors.hpp>
#include <imageplus/math/statistics/histogram.hpp>
#include <imageplus/filters/linear_convolution.hpp>

#include <boost/array.hpp>

namespace imageplus
{
    namespace math
    {
        namespace statistics
        {
            /*!
             * \cond AGIL_TEMPORAL_SOLUTION
             *
             * These classes are only used as a temopral solution (hack) while we don't have
             * a really multidimensional convolution
             */
            template< int Dimension >
            class convolution_traits
            {
            };

            template<>
            class convolution_traits<1>
            {
            public:
                typedef filters::LinearConvolution1D              filter_type;
                typedef filters::LinearConvolution1D::kernel_type kernel_type;
            };

            template<>
            class convolution_traits<2>
            {
            public:
                typedef filters::SeparableLinearConvolution2D              filter_type;
                typedef filters::SeparableLinearConvolution2D::kernel_type kernel_type;
            };

            template<>
            class convolution_traits<3>
            {
            public:
                typedef filters::SeparableLinearConvolution3D              filter_type;
                typedef filters::SeparableLinearConvolution3D::kernel_type kernel_type;
            };



            /*!
             * \endcond
             */

            /*!
             * \brief Class to compute the Probability Density Function (PDF) as a normalized Histogram.
             *
             * \tparam InputModel    : The input type: any ImaVol, Region, etc.
             * \tparam T             : Type of data of the container (by default float64)
             * \tparam HistogramType : Same of Histogram     
             * 
             * \author Jordi Pont <jordi.pont@upc.edu>
             * \date   2010-02-01
             * \author Albert Gil <albert.gil@upc.edu> : Added support for 2D and flexible quantization
             * \date   2011-03-31
             */ 
            template<class InputModel, typename T=float64, class HistogramType = math::statistics::HistogramDefaultType< InputModel > >
            class PDF : public DescriptorBase, 
                        public MultiArray< T, HistogramType::channels >
            {
            public:
                //! The data_type of expected input data
                typedef typename InputModel::data_type data_type;
                 
                //! container type
                typedef MultiArray<T, HistogramType::channels> vd_type;
                
                //! The number of channels of the PDF. \n
                //! Also can be interpreted as the "dimensions" of the PDF, or better, the dimensions of the inherited
                //! MultiArray.
                static const std::size_t channels   = HistogramType::channels;
                 
                //! The dimensions of the InputType. 
                static const std::size_t dimensions = InputModel::dimensions;

                //! Smooth filter type. Dimension depends on channels
                typedef typename convolution_traits<channels>::filter_type convolution_type;
                //! Kernel of the smooth filter. Dimension depends on channels
                typedef typename convolution_traits<channels>::kernel_type kernel_type;

                //! Model for Probability distributions
                static const int32 continuous=0;
                 
                //!
                //! \brief Constructor with min and max value and number of bins
                //! 
                //! The num_bins determine the number of bins used for each channel. 
                //! A uniform quantizer is generated with the 3 input parameters.
                //! The same uniform quantizer is used for each channel.
                //!
                //! \param[in] min_value  : Minimum value of the PDF
                //! \param[in]  max_value : Maximum value of the PDF
                //! \param[in]   num_bins : Number of bins of the PDF
                //! \param[in]   ker      : Kernel to smooth the PDF
                //!
                PDF(data_type min_value = (data_type)0,
                    data_type max_value = (data_type)255,
                    size_type num_bins = (size_type)256,
                    kernel_type ker    = kernel_type() /*filters::Kernel<channels> ker = filters::Kernel<channels>()*/)
                :   DescriptorBase("PDF", true),
                    _conv1d(ker),
                    _kernel(ker)
                {
                    // Create a homogeneous Quantizer, and initialize _array_q whit it
                    Quantizer<data_type> q_map( min_value, max_value, num_bins );
                    for( size_type ii = 0; ii < channels; ++ii )
                    {
                        _array_q[ii] = q_map;
                    }

                	_init();
                }

                /*!
                 * Constructor from a Quantizer
                 *
                 * \param[in] quantizer : the Quantizer to be used for all channels
                 * \param[in] kernel    : a Kernel to smooth the PDF (a delta by default)
                 */
                PDF(Quantizer<data_type> quantizer,
                    kernel_type          kernel    = kernel_type() )
                :   DescriptorBase("PDF", true),
                    _conv1d(kernel),
                    _kernel(kernel)
                {
                    // Create a homogeneous Quantizer, and initialize _array_q whit it
                    for( size_type ii = 0; ii < channels; ++ii )
                    {
                        _array_q[ii] = quantizer;
                    }

                	_init();
                }

                /*!
                 * Constructor from a Quantizers array
                 *
                 * \param[in] quantizer_array : the Quantizers array to be used, one per channel
                 * \param[in] kernel          : a Kernel to smooth the PDF (a delta by default)
                 */
                PDF(boost::array<Quantizer<data_type>, channels > quantizer_array,
                    kernel_type                                   kernel          = kernel_type() )
                :   DescriptorBase("PDF", true),
                    _conv1d(kernel),
                    _kernel(kernel),
                    _array_q(quantizer_array)
                {
                	_init();
                }



                /*! Copy constructor
                 *  \param copy : PDF to be copied
                 */ 
                PDF( const PDF& copy )
                :   DescriptorBase ("PDF", true),
                    vd_type        ((const vd_type&)copy),
                    _conv1d    (copy._conv1d),
                    _kernel    (copy._kernel),
                    _hist_sum  (copy._hist_sum),
                    _array_q   (copy._array_q)
                {   
                }

                /*! Destructor
                 */
                ~PDF()
                {
                }
                
                /*!
                 * Auxiliary function called from the constructors to allocate the necessary memory
                 *
                 * \todo it should be private!
                 */
                void _init()
                {
                	boost::array<std::size_t, channels > _num_bins;

                    // Create _num_bins array based on the quantizer
                    for( size_type ii = 0; ii < channels; ++ii )
                    {
                        _num_bins[ii] = _array_q[ii].num_bins();
                    }

                    // Allocate memory
                    this->resize( _num_bins );
                }

                //! \brief Calculates the PDF of a image given a pair of iterators. 
                //!
                //! \param[in] first : Iterator to the beginning of the region
                //! \param[in] last : Iterator to the end of the region
                //! \param[in] peer_descs : Pointer to CollaborativeDescriptors, in principle is never 0x0 but it is a good idea to ASSERT it
                template< class IteratorModel >
                void calculate(IteratorModel first, IteratorModel last, CollaborativeDescriptors* peer_descs)
                {        
                    ASSERT(peer_descs!=0x0, "PDF calculate: peer_descs must be non null");

                    const math::statistics::Histogram<InputModel,T,HistogramType>& histogram = peer_descs->calculate(new math::statistics::Histogram<InputModel,T,HistogramType>(_array_q), first, last);

                    _conv1d.kernel(_kernel);

                    // Convolve with unnormalized kernel
                    _conv1d.calculate(histogram,*this);


                    // Compute sum
//                        _hist_sum = std::accumulate(this->begin(), this->end(), 0.);
                    T* pd = this->data();
                    _hist_sum = 0.;
                    for(size_t i=0; i< this->num_elements(); ++i) _hist_sum+=*pd++;


                    // Normalize, i.e., convolve with a delta with value 1/_hist_sum
                    // Since we perform a separable convolution,
                    //    the delta value must be the square root of the original value
                    kernel_type tmp_ker;
                    tmp_ker[0] = 1./std::pow(_hist_sum, 1./channels);
                    _conv1d.kernel(tmp_ker);

                    // Convolve with unnormalized kernel
                    _conv1d.calculate(*this,*this);
                }
                
                //! \brief Calculates the PDF the father region given the sons.
                //!
                //! \param[in] son1_descs : CollaborativeDescriptors of the son 1
                //! \param[in] son2_descs : CollaborativeDescriptors of the son 2
                //! \param[in] peer_descs : Pointer to CollaborativeDescriptors, in principle is never 0x0 but it is a good idea to ASSERT it
                void recursive_calculate(CollaborativeDescriptors& son1_descs, CollaborativeDescriptors& son2_descs, CollaborativeDescriptors* peer_descs)
                {        
                    *this =  son1_descs.get(*this) + son2_descs.get(*this);
                }
                
                /*!
                 * \param copy : PDF to be copied
                 *
                 * \return copy, to concatenate
                 */ 
                const PDF& operator=( const PDF& copy)
                {
                	_array_q   = copy._array_q;
                    _conv1d    = copy._conv1d;
                    _hist_sum  = copy._hist_sum;
                    _kernel    = copy._kernel;
                    vd_type::operator=(copy);
                    return copy;
                }

                /*!
                 * \param other : PDF to be summed
                 *
                 * \return the sum of this object plus other
                 */ 
                PDF operator+( const PDF& other ) const
                {
                    PDF out;
                    out._id = _id;
                    out._hist_sum  = hist_sum() + other.hist_sum();

                    out._array_q = other._array_q;
                    
                    out.resize(other.dims());
                    
                    T* p_out = out.data();
                    const T* p_in1 = MultiArray< T, HistogramType::channels >::data();
                    const T* p_in2 = other.data();
                    
                    ASSERT((MultiArray< T,HistogramType::channels>::num_elements()) == other.num_elements(), "PDF sum: Trying tu sum PDF of different sizes");
                    ASSERT((MultiArray< T,HistogramType::channels>::num_elements()) == out.num_elements(), "PDF sum: Something is wrong, out has different size");
                    
                    float64 alpha1 = hist_sum()/(float64)(hist_sum()+other.hist_sum());
                    float64 alpha2 = other.hist_sum()/(float64)(hist_sum()+other.hist_sum());
                    std::size_t n_elem = MultiArray< T, HistogramType::channels >::num_elements();
                    for(std::size_t ii = 0; ii< n_elem; ++ii)
                    {
                        *p_out = alpha1*(*p_in1) + alpha2*(*p_in2);
                        ++p_out; ++p_in1; ++p_in2;
                    }
                    
                    return out;
                }
                
                //! \returns the sum of the unnormalized PDF (to sum PDFs)
                float64 hist_sum() const
                {
                    return _hist_sum;
                }
                
                /*!
                 * \return the internal kernel
                 */
                const filters::Kernel<channels>& kernel() const
                {
                    return _kernel;
                }

                /*!
                 * \returns the quantizers array, one Quantizer per channel
                 */
                const boost::array<Quantizer<data_type>, channels >& quantizer() const
                {
                    return _array_q;
                }

                /*!
                 * \param[in] input_vector : the point to get the probability, represented by a quantized
                 *                           1-D MultiArray
                 *
                 * \return the PDF value of the input_vector
                 *
                 * \todo Do we really need these methods?
                 *       They are just a wrapper to convert to the input_vector type
                 *       to a normal point to access the data.
                 *       This conversion should be done in a different way?
                 */
                template < typename TP >
                const float64 & probability (const MultiArray<TP,1> & input_vector ) const
                {
                	static boost::array< std::size_t, channels> point;
                	//Convert the input vector to a quantized point
                	 for( size_type k = 0; k < channels; k++ )
	                 {
	                     //point[k] = _array_q[k].bin( input_vector[k] );
                		 point[k]=static_cast<std::size_t>(input_vector[k]);
	                 }

                	//return this->operator()(point);
                	return vd_type::operator()(point);
                }


                
            private:
                
                //! Filter to convolve the Histogram with the Kernel
                convolution_type _conv1d;
                
                //! Kernel to convolve            
                //filters::Kernel<channels> _kernel;
                typename convolution_type::kernel_type _kernel;
                
                //! Sum of the unnormalized PDF (to sum PDFs)
                float64 _hist_sum;
                
                //! Quantization array, one quantizer per channel
                boost::array<Quantizer<data_type>, channels > _array_q;
            };
            
            /*!
             * \brief Class to compute the Probability Density Function (PDF) of each channel independently
             *
             * \tparam InputModel     : The input type: any ImaVol, Region, etc.
             * \tparam T : Type of data of the container (by default float64) 
             * 
             * \author Jordi Pont <jordi.pont@upc.edu>
             *
             * \date 01-02-2010
             */ 
            template<class InputModel, typename T=float64>
            class ChannelPDF : public DescriptorBase,
                               public boost::array<PDF<InputModel,T, math::statistics::SingleChannelType>, InputModel::channels>
            {
            public:
            	//! Type of each channel
                typedef PDF<InputModel, T, math::statistics::SingleChannelType> channel_type;
                
                //! Type of the container (array of channel_type)
                typedef boost::array<channel_type, InputModel::channels> vd_type;
                
                //! The data_type of expected input data.
                typedef typename InputModel::data_type data_type;
                
                //!
                //! \brief Constructor with min and max value and number of bins
                //! 
                //! The num_bins determine the number of bins used for each channel. 
                //! A uniform quantizer is generated with the 3 input parameters.
                //! The same uniform quantizer is used for each channel.
                //!
                //! \param[in] min_value  : Minimum value of the ChannelPDF
                //! \param[in]  max_value : Maximum value of the ChannelPDF
                //! \param[in]   num_bins : Number of bins of the ChannelPDF
                //! \param[in]   ker      : Kernel to smooth the ChannelPDF
                ChannelPDF(data_type min_value = 0, data_type max_value = 255, size_type num_bins = 256, filters::Kernel<1> ker = filters::Kernel<1>()) 
                    : DescriptorBase("ChannelPDF", true)
                {
                    for(std::size_t ii=0; ii<InputModel::channels; ++ii)
                    {
                        (*this)[ii] = channel_type(min_value,max_value,num_bins,ker);
                    }
                };
                 
                    
                //!
                //! \brief Constructor with ColorRange, to optimize the quantization to the color range
                //!     A different uniform quantizer is generated for each channel, adapted to its range.
                //!
                //! \param[in]  color_range : Color range for each channel
                //! \param[in]   num_bins   : Number of bins of the ChannelPDF
                //! \param[in]   ker        : Kernel to smooth the ChannelPDF
                ChannelPDF(const ColorRange<InputModel>& color_range, uint64 num_bins = 256, filters::Kernel<1> ker = filters::Kernel<1>()) 
                    :DescriptorBase("ChannelPDF", true)
                {
                    for(std::size_t ii=0; ii<InputModel::channels; ++ii)
                    {
                        (*this)[ii] = channel_type(color_range[ii].min,color_range[ii].max,num_bins,ker);
                    }
                };
                    
                
                //! \brief Calculates the color layout of a image given a pair of iterators. 
                //!
                //! \param[in] first : Iterator to the beginning of the region
                //! \param[in] last : Iterator to the end of the region
                //! \param[in] peer_descs : Pointer to CollaborativeDescriptors, in principle is never 0x0 but it is a good idea to ASSERT it
                //!
                template< class IteratorModel >
                void calculate(IteratorModel first, IteratorModel last, CollaborativeDescriptors* peer_descs)
                {   
                    for(std::size_t ii=0; ii<InputModel::channels; ++ii)
                    {
                        typename IteratorModel::channel_iterator channel_first(first, ii);
                        typename IteratorModel::channel_iterator channel_last(last, ii);

                        CollaborativeDescriptors dummy_descs;
                        (*this)[ii].calculate(channel_first,channel_last, &(dummy_descs));
                        // Without peer_desc, because otherwise the three channels would be
                        // the same (same id PDF) and we would be duplicating data
                        // As a hack, we use an empty dummy_descs
                    }
                }
                
                //! \brief Calculates dominant colors of the father region given the son's ones.
                //!
                //! \param[in] son1_descs : CollaborativeDescriptors of the son 1
                //! \param[in] son2_descs : CollaborativeDescriptors of the son 2
                //! \param[in] peer_descs : Pointer to CollaborativeDescriptors, in principle is never 0x0 but it is a good idea to ASSERT it
                //!
                void recursive_calculate(CollaborativeDescriptors& son1_descs, CollaborativeDescriptors& son2_descs, CollaborativeDescriptors* peer_descs)
                {        
                    *this = son1_descs.get(*this) + son2_descs.get(*this);
                }
                
                /*!
                 *  \param other : ChannelPDF to be summed
                 *
                 *  \return the sum of the object plus the other
                 */ 
                ChannelPDF operator+( const ChannelPDF& other ) const
                {
                    ChannelPDF out;
                    for(std::size_t ii=0; ii<InputModel::channels; ++ii)
                    {
                        out[ii] = (*this)[ii] + other[ii];
                    }
                    return out;
                }
                
    
                /*!
                 * \param channel: Channel whose PDF is returned
                 *
                 * \returns the PDF of a given channel
                 */
                const channel_type& pdf(std::size_t channel) const
                {
                    return (*this)[channel];
                }
                
                /*!
                 * \param channel: Channel whose PDF sum is returned
                 *
                 * \returns the PDF sum before normalizing of a given channel
                 */
                float64 hist_sum(std::size_t channel) const
                {
                    return (*this)[channel].hist_sum();
                }
            };
        }
    }
}

#endif



