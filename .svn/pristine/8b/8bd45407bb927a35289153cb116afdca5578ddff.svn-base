// --------------------------------------------------------------
// Copyright (C)
// Universitat Politecnica de Catalunya (UPC) - Barcelona - Spain
// --------------------------------------------------------------

/*!
 * \file svm_adaptors.cpp
 */

#include <imageplus/cmath.hpp>
#include <boost/foreach.hpp>
#include <imageplus/machine_learning/svm/svm_adaptors.hpp>

using namespace imageplus;
using namespace imageplus::machine_learning::svm;


//struct svm_parameter param;		// set by parse_command_line
//struct svm_problem prob;		// set by read_problem
//struct svm_model *model;
//struct svm_node *x_space;
//int cross_validation;
//int nr_fold;

static char *line = NULL;
static int max_line_len;

//Auxiliar functions and macro definitions
#define Malloc(type,n) (type *)malloc((n)*sizeof(type))

void print_null(const char *s) {}

static void print_verbose(const char *s)
{
	fputs(s,stdout);
	fflush(stdout);
}

static char* readline(FILE *input)
{
	int len;
	
	if(fgets(line,max_line_len,input) == NULL)
		return NULL;

	while(strrchr(line,'\n') == NULL)
	{
		max_line_len *= 2;
		line = (char *) realloc(line,max_line_len);
		len = (int) strlen(line);
		if(fgets(line+len,max_line_len-len,input) == NULL)
			break;
	}
	return line;
}

void exit_input_error(int line_num)
{
	fprintf(stderr,"Wrong input format at line %d\n", line_num);
	exit(1);
}

//******************* REAL _ WRAPPER **********************************
SVM::SVM ()
{
	//Set default parameters
	_param.svm_type = C_SVC;
	_param.kernel_type = RBF;
	_param.degree = 3;
	_param.gamma = 0;	// 1/k
	_param.coef0 = 0;
	_param.nu = 0.5;
	_param.cache_size = 100;
	_param.C = 1;
	_param.eps = 1e-3;
	_param.p = 0.1;
	_param.shrinking = 1;
	_param.probability = 0;
	_param.nr_weight = 0;
	_param.weight_label = NULL;
	_param.weight = NULL;
	_prob.l=0;
	_prob.y=NULL;
	_prob.x=NULL;
	_model=NULL;
	_x_space=NULL;
	_prob_dims = 0;
}

SVM::SVM(const SVM& svm)
{
	_param     = svm._param;
	_prob_dims = svm._prob_dims;

	std::size_t l = _prob.l = svm._prob.l;
	_x_space_elements = svm._x_space_elements;

    if (svm._x_space != NULL)
    {
        _x_space = Malloc(struct svm_node,_x_space_elements);
        memcpy(_x_space, svm._x_space, _x_space_elements*sizeof(SVMNodeType));
    }
    else _x_space = NULL;


	if (svm._prob.y != NULL)
	{
		_prob.y = (double *) malloc(l*sizeof(double));
		memcpy(_prob.y, svm._prob.y, l*sizeof(svm._prob.y));
	}
	else
		_prob.y = NULL;

	if (svm._prob.x != NULL)
	{
//		std::size_t dim;
//		for (dim=0; svm._prob.x[0][dim].index != -1; dim++);
//		dim += 1; // last item (-1)

		_prob.x = (SVMNodeType **) malloc(l*sizeof(SVMNodeType *));
		for (std::size_t i=0; i < l; i++)
		{
			_prob.x[i] = (SVMNodeType *) malloc(_prob_dims*sizeof(SVMNodeType));
			memcpy(_prob.x[i], svm._prob.x[i], _prob_dims*sizeof(SVMNodeType));
		}
	}
	else
		_prob.x = NULL;

	if (svm._model != NULL)
	{
		_model = (ModelType *) calloc(1, sizeof(ModelType));

		// parameter
		_model->param = svm._model->param;

		// number of classes, = 2 in regression/one class svm
		std::size_t nr_class = _model->nr_class = svm._model->nr_class;

		// total #SV
		std::size_t total_sv = _model->l = svm._model->l;

		// 1 if svm_model is created by svm_load_model
		// 0 if svm_model is created by svm_train
		_model->free_sv = svm._model->free_sv;

//		std::size_t dim;
//		for (dim=0; svm._model->SV[0][dim].index != -1; dim++);
//		dim += 1; // last item (-1)

		if (_model->free_sv)
		{
			// SVs (SV[l])
			_model->SV = (SVMNodeType **) malloc(total_sv*sizeof(SVMNodeType *));
			for (size_t i=0; i < total_sv; i++)
			{
				_model->SV[i] = (SVMNodeType *) malloc(_prob_dims*sizeof(SVMNodeType));
				memcpy(_model->SV[i], svm._model->SV[i], _prob_dims*sizeof(SVMNodeType));
			}

			// coefficients for SVs in decision functions (sv_coef[k-1][l])
			_model->sv_coef = (double **) malloc((nr_class-1)*sizeof(double *));
			for (size_t i=0; i < nr_class-1; i++)
			{
				_model->sv_coef[i] = (double *) malloc(total_sv*sizeof(double));
				memcpy(_model->sv_coef[i], svm._model->sv_coef[i], total_sv*sizeof(double));
			}

			// constants in decision functions (rho[k*(k-1)/2])
			int n = nr_class*(nr_class-1)/2;
			if (svm._model->rho != NULL)
			{
				_model->rho = (double *) malloc(n*sizeof(double));
				memcpy(_model->rho, svm._model->rho, n*sizeof(double));
			}
			else
				_model->rho = NULL;

			// pariwise probability information A
			if (svm._model->probA != NULL)
			{
				_model->probA = (double *) malloc(n*sizeof(double));
				memcpy(_model->probA, svm._model->probA, n*sizeof(double));
			}
			else
				_model->probA = NULL;

			// pariwise probability information B
			if (svm._model->probB != NULL)
			{
				_model->probB = (double *) malloc(n*sizeof(double));
				memcpy(_model->probB, svm._model->probB, n*sizeof(double));
			}
			else
				_model->probB = NULL;

			/* Classification Part */
			// label of each class (label[k])
			if (svm._model->label != NULL)
			{
				_model->label = (int *) malloc(nr_class*sizeof(int));
				memcpy(_model->label, svm._model->label, nr_class*sizeof(int));
			}
			else
				_model->label = NULL;

			// number of SVs for each class (nSV[k])
			if (svm._model->nSV != NULL) {
				_model->nSV = (int *) malloc(nr_class*sizeof(int));
				memcpy(_model->nSV, svm._model->nSV, nr_class*sizeof(int));
			} else
				_model->nSV = NULL;
		}
		else
		{
			if(_model->param.svm_type == ONE_CLASS ||
				_model->param.svm_type == EPSILON_SVR ||
				_model->param.svm_type == NU_SVR)
			{
				// SVs (SV[l])
				_model->SV = (SVMNodeType **) malloc(total_sv*sizeof(SVMNodeType *));
				for (size_t i=0; i < total_sv; i++)
				{
					_model->SV[i] = (SVMNodeType *) malloc(_prob_dims*sizeof(SVMNodeType));
					memcpy(_model->SV[i], svm._model->SV[i], _prob_dims*sizeof(SVMNodeType));
				}

				// coefficients for SVs in decision functions (sv_coef[k-1][l])
				_model->sv_coef = (double **) malloc(sizeof(double *));
				_model->sv_coef[0] = (double *) malloc(total_sv*sizeof(double));
				memcpy(_model->sv_coef[0], svm._model->sv_coef[0], total_sv*sizeof(double));

				// constants in decision functions (rho[k*(k-1)/2])
				_model->rho = (double *) malloc(sizeof(double));
				_model->rho[0] = svm._model->rho[0];

				// pariwise probability information
				_model->probA = _model->probB = NULL;
				if (svm._model->probA != NULL)
				{
					_model->probA = (double *) malloc(sizeof(double));
					_model->probA[0] = svm._model->probA[0];
				}

				/* Classification Part */
				// label of each class (label[k])
				_model->label = NULL;

				// number of SVs for each class (nSV[k])
				_model->nSV = NULL;
			}
			else
			{
				// SVs (SV[l])
				_model->SV = (SVMNodeType **) malloc(total_sv*sizeof(SVMNodeType *));
				for (size_t i=0; i < total_sv; i++)
				{
					_model->SV[i] = (SVMNodeType *) malloc(_prob_dims*sizeof(SVMNodeType));
					memcpy(_model->SV[i], svm._model->SV[i], _prob_dims*sizeof(SVMNodeType));
				}

				// coefficients for SVs in decision functions (sv_coef[k-1][l])
				_model->sv_coef = (double **) malloc((nr_class-1)*sizeof(double *));
				for (size_t i=0; i < nr_class-1; i++)
				{
					_model->sv_coef[i] = (double *) malloc(total_sv*sizeof(double));
					memcpy(_model->sv_coef[i], svm._model->sv_coef[i], total_sv*sizeof(double));
				}

				// constants in decision functions (rho[k*(k-1)/2])
				size_t n = (nr_class*(nr_class-1)/2);
				_model->rho = (double *) malloc(n*sizeof(double));
				memcpy(_model->rho, svm._model->rho, n*sizeof(double));

				// pariwise probability information A
				if (svm._model->probA != NULL)
				{
					_model->probA = (double *) malloc(n*sizeof(double));
					memcpy(_model->probA, svm._model->probA, n*sizeof(double));
				}
				else _model->probA = NULL;

				// pariwise probability information B
				if (svm._model->probB != NULL)
				{
					_model->probB = (double *) malloc(n*sizeof(double));
					memcpy(_model->probB, svm._model->probB, n*sizeof(double));
				}
				else _model->probB = NULL;

				/* Classification Part */
				// label of each class (label[k])
				_model->label = (int *) malloc(nr_class*sizeof(int));
				memcpy(_model->label, svm._model->label, nr_class*sizeof(int));

				// number of SVs for each class (nSV[k])
				_model->nSV = (int *) malloc(nr_class*sizeof(int));
				memcpy(_model->nSV, svm._model->nSV, nr_class*sizeof(int));
			}
		}
	}
	else
		_model = NULL;

	_svm_type = svm._svm_type;
	_nr_class = svm._nr_class;
}

#if 0 //AGIL:  recoded by alopez at .hpp file
SVM::~SVM()
{
	if (_model != NULL)
		svm_free_and_destroy_model(&_model);

	if (_prob.y != NULL)
		free(_prob.y);

	if (_prob.x != NULL)
	{
		for (std::size_t i=0; i < (std::size_t)_prob.l; ++i)
			free(_prob.x[i]);

		free(_prob.x);
	}
}
#endif //AGIL

void SVM::train ()
{
	const char * error_msg = svm_check_parameter(&_prob,&_param);

	if(error_msg)
	{
		fprintf(stderr,"Error: %s\n",error_msg);
		exit(-1);
	}
	if (_model!=NULL)  svm_free_and_destroy_model(&_model);
	_model = svm_train(&_prob,&_param);
	_svm_type=svm_get_svm_type(_model);
	_nr_class=svm_get_nr_class(_model);
}

void SVM::cross_validation(const InputType & prob, 
		int32 nr_fold, std::vector<float64> & target)
{
	target.clear();
	float64 *wr_target = Malloc(float64,prob.l); //double
	svm_cross_validation(&prob,&_param,nr_fold,wr_target);
	//Copy *wr_target to target
	float64 * p, *end;
	p=wr_target;
	end=wr_target+prob.l;
	while(p!=end)
		target.push_back(*p++);
	
	free(wr_target);
}

float64 SVM::estimate_f1_score()
{
	/* Run a 2-fold cross-validation experiment that considers all samples */
	std::vector<float64> target;
	cross_validation(_prob, 2, target);

	/* Init counters for true positive (tp), false positive (fp) and false negative (fn) */
	float64 tp = 0, fp = 0, fn = 0;

	/* For every sample that defines the problem... */
	size_t i = 0;
	BOOST_FOREACH(float64 sample, target)
	{
		if (sample == LABEL_POSITIVE)
		{
			if (sample == _prob.y[i]) tp++;
			else fp++;
		}
		else if (sample != _prob.y[i]) fn++;
		i++;
	}

	/* Compute the accuracy as the amount of correctly labeled samples */
	return tp/(2*tp + fn + fp);
}

void SVM::search_parameters()
{
//	if( pSvm->numOfLabels == 2 ) {
//
//		/* Set weights to each class to compensate the unbalanced data */
//		param.nr_weight = pSvm->numOfLabels;
//		param.weight_label = (int *)emalloc( sizeof(int) * param.nr_weight);
//		param.weight = (double *)emalloc( sizeof(double) * param.nr_weight);
//
//		param.weight_label[ 0 ] = LABEL_POSITIVE;
//		param.weight_label[ 1 ] = LABEL_NEGATIVE;
//
//		int numOfSamples = numOfObsPos + numOfObsNeg;
//		param.weight[ 0 ] = (double)numOfObsPos/(double)(numOfSamples);
//		param.weight[ 1 ] = (double)numOfObsNeg/(double)(numOfSamples);
//
//		//param.weight[ 1 ] = (double)numOfObsNeg;
//	}

	/*****************************************/
	/* Grid search of gamma and C parameters */
	/*****************************************/
	// Alexander C. Loui, Jiebo Luo, Shih-Fu Chang, Dan Ellis, Wei Jiang, Lyndon Kennedy, Keansub Lee, Akira Yanagawa. Kodak's Consumer Video Benchmark Data Set: Concept Definition and Annotation. In  ACM SIGMM International Workshop on Multimedia Information Retrieval, Germany, September 2007

	float64 l = std::log2(1.0/_dimension);
	float64 k = floor(l + 0.5); /* equivalent to round(l) */

	double bestGamma = pow(2, k);
	double bestC = 1;
	float64 bestEvaluation = 0;
	int i, j;

	if (_prob.l > 1) {
		/* For each considered gamma */
		for (i=-4; i<=4; i+=2) {
			_param.gamma = pow(2, k + i);

			/* For each considered C */
			for (j=0; j<=10; j+=2) {
				_param.C = std::pow(2, j);

				/* Check parameters */
				const char* message = svm_check_parameter(&_prob, &_param);
				if(message != NULL)
					throw ImagePlusError("WARNING (svm_adaptors): " + std::string(message));

				// Compute the expected accuracy with the current gamma and C parameters
				float64 evaluation = estimate_f1_score();

				// If the computed accuracy is the best so far...
				if(evaluation > bestEvaluation) {
					// ...save the gamma and C parameters
					bestGamma = _param.gamma;
					bestC = _param.C;
				}
			}
		}
	}
	else
		throw ImagePlusError("WARNING (svm_adaptors): Not enough samples to estimate gamma and C parameters through cross-validation.");

	/* Train model with the best C and gamma */
	_param.gamma = bestGamma;
	_param.C = bestC;
}

void SVM::save (const std::string & filename)
{
	svm_save_model(filename.c_str(),_model);
}

void SVM::open (const std::string & filename)
{
	if (_model!=NULL)
	{
		svm_free_and_destroy_model(&_model);
		_model=NULL;
	}
	_model=svm_load_model(filename.c_str());
	if (!_model)
	{
		throw ImagePlusError("Error while loading SVM model");
	}
}

void SVM::read_data_libsvm ( const std::string & filename )
{
	int max_index, inst_max_index, i, j;
	FILE *fp = fopen(filename.c_str(),"r");
	char *endptr;
	char *idx, *val, *label;

	if(fp == NULL)
	{
		fprintf(stderr,"can't open input file %s\n",filename.c_str());
		exit(1);
	}

	_prob.l = 0;
	_x_space_elements = 0;

	max_line_len = 1024;

	if (line!=NULL) free(line);

	line = Malloc(char,max_line_len);
	while(readline(fp)!=NULL)
	{
		char *p = strtok(line," \t"); // label

		// features
		while(1)
		{
			p = strtok(NULL," \t");
			if(p == NULL || *p == '\n') // check '\n' as ' ' may be after the last feature
				break;
			++_x_space_elements;
		}
		++_x_space_elements;
		++_prob.l;
	}
	rewind(fp);

	//_free_prob();

	if (_prob.y!=NULL)
	{
		free (_prob.y);
		_prob.y=NULL;
	}

	if (_prob.x!=NULL)
	{

		free(_prob.x);
		_prob.x=NULL;
	}

	if(_x_space!=NULL)
	{
		free(_x_space);
		_x_space=NULL;
	}

	_prob.y = Malloc(double,_prob.l);
	_prob.x = Malloc(struct svm_node *,_prob.l);
	_x_space = Malloc(struct svm_node,_x_space_elements);

	max_index = 0;
	j=0;
	for(i=0;i<_prob.l;i++)
	{
		inst_max_index = -1; // strtol gives 0 if wrong format, and precomputed kernel has <index> start from 0
		readline(fp);
		_prob.x[i] = &_x_space[j];
		label = strtok(line," \t");
		_prob.y[i] = strtod(label,&endptr);
		if(endptr == label)
			exit_input_error(i+1);

		while(1)
		{
			idx = strtok(NULL,":");
			val = strtok(NULL," \t");

			if(val == NULL)
				break;

			errno = 0;
			_x_space[j].index = (int) strtol(idx,&endptr,10);
			if(endptr == idx || errno != 0 || *endptr != '\0' || _x_space[j].index <= inst_max_index)
				exit_input_error(i+1);
			else
				inst_max_index = _x_space[j].index;

			errno = 0;
			_x_space[j].value = strtod(val,&endptr);
			if(endptr == val || errno != 0 || (*endptr != '\0' && !isspace(*endptr)))
				exit_input_error(i+1);

			++j;
		}

		if(inst_max_index > max_index)
			max_index = inst_max_index;
		_x_space[j++].index = -1;
	}

	if(_param.gamma == 0 && max_index > 0)
		_param.gamma = 1.0/max_index;

	if(_param.kernel_type == PRECOMPUTED)
		for(i=0;i<_prob.l;i++)
		{
			if (_prob.x[i][0].index != 0)
			{
				fprintf(stderr,"Wrong input format: first column must be 0:sample_serial_number\n");
				exit(1);
			}
			if ((int)_prob.x[i][0].value <= 0 || (int)_prob.x[i][0].value > max_index)
			{
				fprintf(stderr,"Wrong input format: sample_serial_number out of range\n");
				exit(1);
			}
		}

	fclose(fp);
	
}

SVM & SVM::operator=(const SVM & other)
{
	_param     = other._param;
	_prob_dims = other._prob_dims;

	size_t l = _prob.l = other._prob.l;

	if (other._prob.y != NULL)
	{
		if (_prob.y == NULL)
			_prob.y = (double *) malloc(l*sizeof(double));
		memcpy(_prob.y, other._prob.y, l*sizeof(double));
	}

	if (other._prob.x != NULL)
	{
//		std::size_t dim;
//		for (dim=0; other._prob.x[0][dim].index != -1; dim++);
//		dim += 1; // last item (-1)

		if (_prob.x == NULL)
		{
			_prob.x = (SVMNodeType **) malloc(l*sizeof(SVMNodeType *));
			for (std::size_t i=0; i < l; ++i)
				_prob.x[i] = (SVMNodeType *) malloc(_prob_dims*sizeof(SVMNodeType));
		}
		for (std::size_t i=0; i < l; ++i)
			memcpy(_prob.x[i], other._prob.x[i], _prob_dims*sizeof(SVMNodeType));
	}

	if (other._model != NULL)
	{
		if (_model == NULL)
			_model = (ModelType *) calloc(1, sizeof(ModelType));

		// parameter
		_model->param = other._model->param;

		// number of classes, = 2 in regression/one class svm
		std::size_t nr_class = _model->nr_class = other._model->nr_class;

		// total #SV
		std::size_t total_sv = _model->l = other._model->l;

		// 1 if svm_model is created by svm_load_model
		// 0 if svm_model is created by svm_train
		_model->free_sv = other._model->free_sv;

//		std::size_t dim;
//		for (dim=0; other._model->SV[0][dim].index != -1; dim++);
//		dim += 1; // last item (-1)

		if (_model->free_sv)
		{
			// SVs (SV[l])
			if (_model->SV == NULL)
			{
				_model->SV = (SVMNodeType **) malloc(total_sv*sizeof(SVMNodeType *));
				for (size_t i=0; i < total_sv; i++)
					_model->SV[i] = (SVMNodeType *) malloc(_prob_dims*sizeof(SVMNodeType));
			}
			for (size_t i=0; i < total_sv; i++)
				memcpy(_model->SV[i], other._model->SV[i], _prob_dims*sizeof(SVMNodeType));

			// coefficients for SVs in decision functions (sv_coef[k-1][l])
			if (_model->sv_coef == NULL)
			{
				_model->sv_coef = (double **) malloc((nr_class-1)*sizeof(double *));
				for (size_t i=0; i < nr_class-1; i++)
					_model->sv_coef[i] = (double *) malloc(total_sv*sizeof(double));
			}
			for (size_t i=0; i < nr_class-1; i++)
				memcpy(_model->sv_coef[i], other._model->sv_coef[i], total_sv*sizeof(double));

			// constants in decision functions (rho[k*(k-1)/2])
			int n = nr_class*(nr_class-1)/2;
			if (other._model->rho != NULL)
			{
				if (_model->rho == NULL)
					_model->rho = (double *) malloc(n*sizeof(double));
				memcpy(_model->rho, other._model->rho, n*sizeof(double));
			}
			else
				_model->rho = NULL;

			// pariwise probability information A
			if (other._model->probA != NULL)
			{
				if (_model->probA == NULL)
					_model->probA = (double *) malloc(n*sizeof(double));
				memcpy(_model->probA, other._model->probA, n*sizeof(double));
			}
			else
				_model->probA = NULL;

			// pariwise probability information B
			if (other._model->probB != NULL)
			{
				if (_model->probB == NULL)
					_model->probB = (double *) malloc(n*sizeof(double));
				memcpy(_model->probB, other._model->probB, n*sizeof(double));
			}
			else
				_model->probB = NULL;

			/* Classification Part */
			// label of each class (label[k])
			if (other._model->label != NULL)
			{
				if (_model->label == NULL)
					_model->label = (int *) malloc(nr_class*sizeof(int));
				memcpy(_model->label, other._model->label, nr_class*sizeof(int));
			}
			else
				_model->label = NULL;

			// number of SVs for each class (nSV[k])
			if (other._model->nSV != NULL) {
				if (_model->nSV == NULL)
					_model->nSV = (int *) malloc(nr_class*sizeof(int));
				memcpy(_model->nSV, other._model->nSV, nr_class*sizeof(int));
			} else
				_model->nSV = NULL;
		}
		else
		{
			if(_model->param.svm_type == ONE_CLASS ||
				_model->param.svm_type == EPSILON_SVR ||
				_model->param.svm_type == NU_SVR)
			{
				// SVs (SV[l])
				if (_model->SV == NULL)
				{
					_model->SV = (SVMNodeType **) malloc(total_sv*sizeof(SVMNodeType *));
					for (size_t i=0; i < total_sv; i++)
						_model->SV[i] = (SVMNodeType *) malloc(_prob_dims*sizeof(SVMNodeType));
				}
				for (size_t i=0; i < total_sv; i++)
					memcpy(_model->SV[i], other._model->SV[i], _prob_dims*sizeof(SVMNodeType));

				// coefficients for SVs in decision functions (sv_coef[k-1][l])
				if (_model->sv_coef == NULL)
					_model->sv_coef = (double **) malloc(sizeof(double *));
				_model->sv_coef[0] = (double *) malloc(l*sizeof(double));

				// constants in decision functions (rho[k*(k-1)/2])
				if (_model->rho == NULL)
					_model->rho = (double *) malloc(sizeof(double));
				_model->rho[0] = other._model->rho[0];

				// pariwise probability information
				_model->probA = _model->probB = NULL;
				if (other._model->probA != NULL)
				{
					if (_model->probA == NULL)
						_model->probA = (double *) malloc(sizeof(double));
					_model->probA[0] = other._model->probA[0];
				}

				/* Classification Part */
				// label of each class (label[k])
				_model->label = NULL;

				// number of SVs for each class (nSV[k])
				_model->nSV = NULL;
			}
			else
			{
				// SVs (SV[l])
				if (_model->SV == NULL)
				{
					_model->SV = (SVMNodeType **) malloc(total_sv*sizeof(SVMNodeType *));
					for (size_t i=0; i < total_sv; i++)
						_model->SV[i] = (SVMNodeType *) malloc(_prob_dims*sizeof(SVMNodeType));
				}
				for (size_t i=0; i < total_sv; i++)
					memcpy(_model->SV[i], other._model->SV[i], _prob_dims*sizeof(SVMNodeType));

				// coefficients for SVs in decision functions (sv_coef[k-1][l])
				if (_model->sv_coef == NULL)
				{
					_model->sv_coef = (double **) malloc((nr_class-1)*sizeof(double *));
					for (size_t i=0; i < nr_class-1; i++)
						_model->sv_coef[i] = (double *) malloc(total_sv*sizeof(double));
				}
				for (size_t i=0; i < nr_class-1; i++)
					memcpy(_model->sv_coef[i], other._model->sv_coef[i], total_sv*sizeof(double));

				// constants in decision functions (rho[k*(k-1)/2])
				size_t n = (nr_class*(nr_class-1)/2);
				if (_model->rho == NULL)
					_model->rho = (double *) malloc(n*sizeof(double));
				memcpy(_model->rho, other._model->rho, n*sizeof(double));

				// pariwise probability information A
				if (other._model->probA != NULL)
				{
					if (_model->probA == NULL)
						_model->probA = (double *) malloc(n*sizeof(double));
					memcpy(_model->probA, other._model->probA, n*sizeof(double));
				}
				else _model->probA = NULL;

				// pariwise probability information B
				if (other._model->probB != NULL)
				{
					if (_model->probB == NULL)
						_model->probB = (double *) malloc(n*sizeof(double));
					memcpy(_model->probB, other._model->probB, n*sizeof(double));
				}
				else _model->probB = NULL;

				/* Classification Part */
				// label of each class (label[k])
				if (_model->label == NULL)
					_model->label = (int *) malloc(nr_class*sizeof(int));
				memcpy(_model->label, other._model->label, nr_class*sizeof(int));

				// number of SVs for each class (nSV[k])
				if (_model->nSV == NULL)
					_model->nSV = (int *) malloc(nr_class*sizeof(int));
				memcpy(_model->nSV, other._model->nSV, nr_class*sizeof(int));
			}
		}
	}
	else
		_model = NULL;

	_svm_type = other._svm_type;
	_nr_class = other._nr_class;
	
	return *this;
}

void SVM::quiet_mode()
{
	svm_set_print_string_function(&print_null);
}

void SVM::verbose_mode()
{
	svm_set_print_string_function(&print_verbose);
}


imageplus::machine_learning::svm::SVMCrossValidationFigures imageplus::machine_learning::svm::cross_validation_accuracy( SVM & svm, int32 nr_folds )
{
	int32 i;
	int32 total_correct = 0;
	float64 total_error = 0;
	float64 sumv = 0, sumy = 0, sumvv = 0, sumyy = 0, sumvy = 0;
	
	std::vector<float64> target;
	svm.cross_validation(svm.input_data(), nr_folds, target);
	
	SVMCrossValidationFigures result;
	result.svm_type=svm.parameters().svm_type;
	
	if(svm.parameters().svm_type == EPSILON_SVR ||
	   svm.parameters().svm_type == NU_SVR)
	{
		for(i=0;i< svm.input_data().l;i++)
		{
			float64 y = svm.input_data().y[i];
			float64 v = target[i];
			total_error += (v-y)*(v-y);
			sumv += v;
			sumy += y;
			sumvv += v*v;
			sumyy += y*y;
			sumvy += v*y;
		}

		result.mse = total_error/svm.input_data().l;

		result.squared_correlation_coeff=((svm.input_data().l*sumvy-sumv*sumy)*(svm.input_data().l*sumvy-sumv*sumy))/
		((svm.input_data().l*sumvv-sumv*sumv)*(svm.input_data().l*sumyy-sumy*sumy));
	}
	else
	{
		for(i=0;i<svm.input_data().l;i++)
			if(target[i] == svm.input_data().y[i])
				++total_correct;
		
		//return total_correct/svm.input_data().l
		result.accuracy=static_cast<float64>(total_correct)/svm.input_data().l;
	}
	
	return result;
}

