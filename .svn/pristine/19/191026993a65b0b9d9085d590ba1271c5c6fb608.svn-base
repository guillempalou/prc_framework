// --------------------------------------------------------------
// Copyright (C)
// Universitat Politecnica de Catalunya (UPC) - Barcelona - Spain
// --------------------------------------------------------------

//!
//!  \file multiview.cpp
//!
//! \author Marcel Alcoverro <marcel@gps.tsc.upc.edu>
//!
//!
//!

//#include <imageplus/core.hpp>

#include <imageplus/multiview.hpp>
#include <multiview_auxiliar.hpp>
#include <imageplus/math/numeric/transformations.hpp>
#include <imageplus/math/numeric/products.hpp>
#include <imageplus/multiview/camera_implementations.hpp>

using namespace imageplus;
using namespace imageplus::multiview;
using namespace imageplus::math::numeric;
using namespace imageplus::math::geometry;

void  imageplus::multiview::fast_world2image( const Point3D & p3d, const Camera& cam, Point2D & out)
{
    Point3D temp;

    
    // Matrix product
    // TODO: Use math functions (faster?)
    const float64 *pdP= cam.p().data();
    temp.x() = pdP[0]*p3d.x() + pdP[1]*p3d.y() + pdP[2] *p3d.z() +pdP[3];
    temp.y() = pdP[4]*p3d.x() + pdP[5]*p3d.y() + pdP[6] *p3d.z() +pdP[7];
    temp.z() = pdP[8]*p3d.x() + pdP[9]*p3d.y() + pdP[10]*p3d.z() +pdP[11];

    // X=X/Z, Y=Y/Z
    Point2D p2d(temp.x()/temp.z(), temp.y()/temp.z());

    // Add distortion
    ideal_to_distorted( p2d, cam, out);
    

}

bool imageplus::multiview::fast_world2image_assert(const Point3D & p3d, const Camera& cam, Point2D & out)
{
    fast_world2image(p3d, cam, out);

    Coord2D<> coord(out.x(), out.y());
    
    return (coord.x()<cam.im_width() && coord.y()<cam.im_height() && coord.x()>0 && coord.y()>0);
}

Point3D imageplus::multiview::images2world(const MultiView<Point2D>& mv_points, const MultiView<uint8>& is_in_cam) throw (ImagePlusMultiviewVisibility)
{
    // TODO: Assert or check cameras of diferents MultiView<> inputs
    
    int32 count=0;
    uint32 i;
    float64 alpha_ray_distance = 0.5;

    // check if the visibility condition is fulfilled
    for (i = 0; i < mv_points.size(); i++)
    {
        if (is_in_cam(i))
        {
            count++;
        }
    }
    // process each object that was seen by at least two cameras
    if (count < 2) throw ImagePlusMultiviewVisibility("images2world: point is seen by less than 2 cameras.");
    return min_ray_distance_error_3d_point_outlier_rej(mv_points, is_in_cam, alpha_ray_distance);

}

MultiArray<float64,2> imageplus::multiview::fundamental_matrix(const Camera& cam1, const Camera& cam2)
{
    //Compute Camera 1 COP: C1
    MultiArray<float64,1> C1temp = prod(trans(cam1.rot()),cam1.trans());
    MultiArray<float64,1> C1(4);
    C1.data()[0] = - C1temp.data()[0];
    C1.data()[1] = - C1temp.data()[1];
    C1.data()[2] = - C1temp.data()[2];
    C1.data()[3] = 1.0;
    
    //Compute pseudoInvP1:
    MultiArray<float64,2> P1T = trans(cam1.p());
    MultiArray<float64,2> pseudoInvP1 = prod(P1T, invert_matrix(prod(cam1.p(),P1T)));

    //Compute epipole of Image 2
    MultiArray<float64,1> e2 = prod(cam2.p(), C1);

    //Compute FundamentalMatrix
    MultiArray<float64,2> P2pseudoInvP1 = prod(cam2.p(), pseudoInvP1);
    //Note: F12col1 = e2 x P2pseudoInvP1col1
    //      F12col2 = e2 x P2pseudoInvP1col2    
    //      F12col3 = e2 x P2pseudoInvP1col3
    MultiArray<float64,2> F12(3,3);
    for( int64 i = 0; i < 3; i++ )
    {
        F12[i][0] = P2pseudoInvP1[i][2] * e2.data()[1] - P2pseudoInvP1[i][1] * e2.data()[2];
        F12[i][1] = P2pseudoInvP1[i][0] * e2.data()[2] - P2pseudoInvP1[i][2] * e2.data()[0];
        F12[i][2] = P2pseudoInvP1[i][1] * e2.data()[0] - P2pseudoInvP1[i][0] * e2.data()[1];
    }
    
    return F12;
}

Point3D imageplus::multiview::epipolar_line_from_fundamental_matrix_undistorted(const Point2D& x1, const MultiArray<float64,2>& F12)
{
    Point3D pt1;
    pt1.x() = x1.x();
    pt1.y() = x1.y();
    pt1.z() = 1.0;

    Point3D line2 = prod(F12, pt1);
    float64 norm = 1.0 / std::sqrt(line2.x() * line2.x() + line2.y() * line2.y()); 
    line2.x() *= norm;
    line2.y() *= norm;
    line2.z() *= norm;
    
    return line2;
}

Line2D<int16> imageplus::multiview::epipolar_line_samples( const Camera & cam, const Point3D & eline )
{
    float64 xmax=static_cast<float64>( cam.im_width() );
    float64 ymax=static_cast<float64>( cam.im_height() );
    
    const float64 * l=eline.data();
    
    float64 x[2], y[2];
    float64 xt[2]={0,xmax-1};
    float64 yt[2]={0,ymax-1};
    int64 v=0;
    for( int64 i=0; i < 2; ++i )
    {
        y[v]=-(l[2]+l[0]*xt[i])/l[1];
        if( y[v] >= 0 && y[v] <= ymax )
        {
            x[v]=xt[i];
            if( y[v] == ymax )
            {
                --y[v];
            }
            ++v;
        }
    }
    if( v < 2 )
    {
        for( int64 i=0; i < 2; ++i )
        {
            x[v]=-(l[2]+l[1]*yt[i])/l[0];
            if( x[v] >= 0 && x[v] <= xmax )
            {
                y[v]=yt[i];
                if( x[v] == xmax )
                {
                    --x[v];
                }
                ++v;
                if( v == 2 )
                {
                    break;
                }
            }
        }
    }
    if( v != 2 )
    {
        return Line2D<int16>();
    }
    Coord<int16,2> c1( static_cast<int16>( x[0] ), static_cast<int16>( y[0] ) );
    Coord<int16,2> c2( static_cast<int16>( x[1] ), static_cast<int16>( y[1] ) );
    
    return Line2D<int16>( c1, c2 );
}

void imageplus::multiview::world_to_image_undistorted( const Point3D & p3d, const Camera & cam, Point2D & out )
{
    float64 dX=p3d.x();
    float64 dY=p3d.y();
    float64 dZ=p3d.z();
    const float64 * pdP=cam.p().data();
    float64 z=1.0/(pdP[8]*dX+pdP[9]*dY+pdP[10]*dZ+pdP[11]);
    out.x()=z*(pdP[0]*dX+pdP[1]*dY+pdP[2]*dZ+pdP[3]);
    out.y()=z*(pdP[4]*dX+pdP[5]*dY+pdP[6]*dZ+pdP[7]);
}

void imageplus::multiview::two_cameras_triangulation( const Camera & c1, const Camera & c2, const Point2D & p1, const Point2D & p2, float64 & d1, float64 & d2, Point3D & out )
{
    Point3D cop1, cop2;
    Point3D v1, v2;
    back_projected_ray( c1, p1, cop1, v1 );
    back_projected_ray( c2, p2, cop2, v2 );
    
    two_cameras_triangulation( v1, v2, cop1, cop2, d1, d2, out );
}

void imageplus::multiview::two_cameras_triangulation( const Point3D & v1, const Point3D & v2, const Point3D & cop1, const Point3D & cop2, float64 & d1, float64 & d2, Point3D & out )
{
    float64 b=scalar_prod( v1, v2 );
    float64 d=scalar_prod( v1, cop1-cop2 );
    float64 e=scalar_prod( v2, cop1-cop2 );
    float64 denom=1.0/(1.0-b*b);
    d1=denom*(b*e-d);
    d2=denom*(e-b*d);
    Point3D m1=cop1+d1*v1;
    Point3D m2=cop2+d2*v2;
    out=0.5*(m1+m2);
}

float64 imageplus::multiview::point_depth( const Point3D & p, const Camera & cam )
{
    const float64 * c=&cam.p().data()[8];
    return c[0]*p[0]+c[1]*p[1]+c[2]*p[2]+c[3];
}
