/*
 * image_test.cpp
 *
 *  Created on: Sep 5, 2012
 *      Author: guillem
 */

#include <imageplus/core/image_signal.hpp>
#include <imageplus/core/video_signal.hpp>
#include <imageplus/core/colorspace_converter.hpp>
#include <imageplus/core/opencv.hpp>

#include <imageplus/segmentation/partition/partition.hpp>
#include <imageplus/segmentation/visualization/false_color.hpp>

#include <imageplus/video_segmentation/trajectory_bpt/trajectory.hpp>
#include <imageplus/video_segmentation/trajectory_bpt/motion_color_distance.hpp>
#include <imageplus/video_segmentation/trajectory_bpt/motion_color_model_distance.hpp>
#include <imageplus/video_segmentation/trajectory_bpt/motion_color_histogram_distance.hpp>

#include <imageplus/optical_flow/flow_io.hpp>
#include <imageplus/optical_flow/trajectory_tracking.hpp>

#include <imageplus/bpt/binary_partition_tree.hpp>
#include <imageplus/bpt/models/mean_color_distance.hpp>

#include <boost/filesystem.hpp>
#include <imageplus/toolbox/tictoc.hpp>

#include <iostream>
#include <iomanip>
#include <stdio.h>
#include <stdlib.h>
#include <math.h>

using namespace imageplus;

#define uint64 imageplus::uint64
#define int64 imageplus::int64

typedef VideoSignal<float64,3> 																						VideoType;
typedef VideoSignal<float64,3>::ImageType																			FrameType;
typedef VideoSignal<float64,2>																						OpticalFlowType;
typedef OpticalFlowType::ImageType																					OpticalFlowFrame;

typedef VideoType::coord_type 																						coord3d;

// The vector is of the same type
typedef VideoType::value_type																						lab_type;
typedef VideoType::value_type																						rgb_type;

typedef video_segmentation::Trajectory<VideoType> 																	TrajectoryType;

typedef bpt::BinaryPartitionTree<VideoType, bpt::NumberOfRegionsStopCondition, TrajectoryType, Connectivity3D2>		BPTAlgorithm1;
typedef bpt::BinaryPartitionTree<VideoType, bpt::NumberOfRegionsStopCondition, TrajectoryType, Connectivity3D2>		BPTAlgorithm2;
typedef BPTAlgorithm1::BPT																							BPT;
typedef BPTAlgorithm1::PartitionType																				PartitionType;

//typedef MeanColorDistanceModel<VideoType, TrajectoryType>	 DistanceModelType;
typedef video_segmentation::MotionColorDistanceModel<VideoType, TrajectoryType, OpticalFlowType> 					MeanDistanceModelType;
typedef video_segmentation::MotionColorHistogramDistance<VideoType, TrajectoryType, OpticalFlowType> 				HistDistanceModelType;
typedef video_segmentation::MotionColorModelDistance<VideoType, TrajectoryType, OpticalFlowType> 					ModelDistanceModelType;

VideoType convert_map_to_image(VideoSignal<float64,1>& s) {
	VideoType res(s.sizes());
	for (VideoSignal<float64,1>::iterator p = s.begin(); p!=s.end(); ++p) {
		coord3d pos = p.pos();
		float64 value = (*p)(0);

		res(pos) = value*rgb_type(255,255,255);
	}

	return res;
}

VideoType print_trajectories(VideoType& v, PartitionType& p, BPT& bpt) {

	VideoType trajectories(v.sizes());

	PartitionType::iterator pos = p.begin();
	PartitionType::iterator pos_end = p.end();

	lab_type red(0,0,255);
	lab_type green(0,255,0);

	float64 Nframes = v.length();
	for (; pos!=pos_end; ++pos) {
		coord3d voxel = pos.pos();
		lab_type color;
		//std::cout << "Region " << (*pos)(0) << std::endl;
		uint64 l = bpt((*pos)(0)).length();
		if (l > 1) {
			float64 perc = l*1.0 / Nframes;
			color = (1-perc)*red + perc*green;
		} else {
			color = 0.4*v(voxel);

		}
		trajectories(voxel) = color;
	}

	return trajectories;
}

float64 estimate_motion_damping(OpticalFlowType& flow) {

	OpticalFlowType::iterator p = flow.begin();
	OpticalFlowType::iterator end = flow.end();

	typedef OpticalFlowType::coord_type coord_type;

	float64 d = 5;

	float64 max_dist = 0;
	float64 av_dist = 0;
	float64 N = 0;
	for (; p != end; ++p) {
		coord_type radius = p.pos(); radius.fill(d); radius(2) = 0;
		coord_type center = p.pos();
		coord_type upper = center - radius;
		coord_type lower = center + radius;
		float64 av_d = 0;
		float64 n = 0;
		for (OpticalFlowType::roi_iterator x = flow.roi_begin(upper,lower); x != flow.roi_end(upper,lower); ++x) {
			if (flow.inside(x.pos())) {
				float64 w = std::exp(-(p.pos() - x.pos()).squaredNorm() / 4);
				if (w == 1) continue;
				float64 dist = ((*p) - (*x)).norm();

				av_dist+= w*dist;
				av_d += w*dist;

				N+=w;
				n+=w;
			}
		}
		av_d /= n;

		max_dist= (av_d > max_dist) ? av_d : max_dist;
	}

	return max_dist;
}

float64 estimate_color_damping(VideoType& video) {

	VideoType::iterator p = video.begin();
	VideoType::iterator end = video.end();

	typedef VideoType::coord_type coord_type;

	float64 d = 5;

	float64 max_dist = 0;
	float64 av_dist = 0;
	float64 N = 0;
	for (; p != end; ++p) {
		coord_type radius = p.pos(); radius.fill(d); radius(2) = 0;
		coord_type center = p.pos();
		coord_type upper = center - radius;
		coord_type lower = center + radius;
		float64 av_d = 0;
		float64 n = 0;
		for (VideoType::roi_iterator x = video.roi_begin(upper,lower); x != video.roi_end(upper,lower); ++x) {
			if (video.inside(x.pos())) {
				float64 w = std::exp(-(p.pos() - x.pos()).squaredNorm() / 4);
				if (w == 1) continue;
				float64 dist = ((*p) - (*x)).norm();

				av_dist+= w*dist;
				av_d += w*dist;

				N+=w;
				n+=w;
			}
		}
		av_d /= n;
		max_dist= (av_d > max_dist) ? av_d : max_dist;
	}

	return max_dist;
}

void add_temporal_neighbors(VideoType& video, BPT& bpt, OpticalFlowType& forward_flows, OpticalFlowType& backward_flows, PartitionType& part, uint64 type) {

	for (BPT::leaves_iterator r = bpt.begin(); r != bpt.end(); ++r) {
		BPT::RegionType& reg = *r;
		int64 start = reg.frame_begin();
		int64 end = reg.frame_end();

		//Check for bounds
		const coord3d& lower = video.lower_point();
		const coord3d& upper = video.upper_point();

		for (BPT::RegionType::iterator p = reg.begin(); p != reg.end(); ++p) {
			int64 frame = (*p)(2);
			coord3d pos;

			if (frame == start) {
				pos = coord3d(round((*p)(0)+backward_flows(*p)(0)),round((*p)(1)+backward_flows(*p)(1)),start-1);

				if (type == 2)
					pos = coord3d((*p)(0),(*p)(1),start-1);

				//Check fo bounds
				coord3d a = pos - lower;
				coord3d b = upper - pos;

				// Check if the interpolating point is outside
				if (a.minCoeff() < 0 || b.minCoeff() < 0) {
					continue;
				}

				//std::cout << " b " << pos.transpose() << " " << (*p).transpose() << " " << part(pos).value()(0) << std::endl;

				BPT::RegionType& n = bpt(part(pos)(0));
				if (!reg.is_neighbor(&n) && (part(pos)(0) != part((*p))(0))) {
					reg.add_neighbor(&n);
				}
			}

			if (frame == end) {
				pos = coord3d(round((*p)(0)+forward_flows(*p)(0)),round((*p)(1)+forward_flows(*p)(1)),end+1);

				if (type == 2)
					pos = coord3d((*p)(0),(*p)(1),start+1);

				//Check for bounds
				coord3d a = pos - lower;
				coord3d b = upper - pos;

				// Check if the interpolating point is outside
				if (a.minCoeff() < 0 || b.minCoeff() < 0) {
					continue;
				}
				//std::cout << " f " << pos.transpose() << " " << (*p).transpose() <<  " " << part(pos).value()(0) << std::endl;
				BPT::RegionType& n = bpt(part(pos)(0));

				if (!reg.is_neighbor(&n)  && (part(pos)(0) != part((*p))(0))) {
					reg.add_neighbor(&n);
				}
			}

		}
	}
}

int main(int argc, char* argv[]) {

	uint64 start = atoi(argv[1]);
	uint64 end = atoi(argv[2]);
	uint64 type = atoi(argv[3]);
	float64 pcolor = atof(argv[4]);
	float64 pmotion = atof(argv[5]);

	std::string path = argv[6];
	std::string result = argv[7];

	uint64 K = end+1;
	uint64 step = K;

	// create the necessary paths
	boost::filesystem::path result_path(result);

	boost::filesystem::create_directory(result_path);
	boost::filesystem::create_directory(result_path / "over_segmentation");
	boost::filesystem::create_directory(result_path / "segmentations");
	boost::filesystem::create_directory(result_path / "trajectories");
	boost::filesystem::create_directory(result_path / "damping_factor");
	boost::filesystem::create_directory(result_path / "occlusions");
	boost::filesystem::create_directory(result_path / "flow_variation");
	boost::filesystem::create_directory(result_path / "flow_reliability");
	boost::filesystem::create_directory(result_path / "structure_tensor");
	//boost::filesystem::create_directory(p / "trees");

	//The algorithm assumes that the directory is structured
	// BasePath /
	//			/Frames/frame000.png ...
	//  		/Flows/flow_0_1.png
	for (uint64 i = start; i <= end; i+=step) {
		uint64 Nframes = std::min(K, end-i+1);
		std::cout << "Segmenting " << Nframes << " frames" << std::endl;
		VideoType video(Nframes);

		//Read frames
		for (uint64 k = i; k <= end; k++) {
			std::ostringstream os;
			os << path << "/frames/frame" << std::setw(3) << std::setfill('0') << k << ".png";
			video.read_frame(os.str(),k-i); // read frame k and put it to the position k-i of the current block

			// Filter it by a small gaussian to reduce a little noise
			//FrameType frame = video.frame(k-i);
			//cv::Mat b = to_opencv(frame);
			//cv::GaussianBlur(b, b, cv::Size(7,7), 0.5, 0.5);
		}
		ColorSpaceConverter<VideoType> converter;
		converter.convert(video, ColorSpaceLAB);

		uint64 sx = video.size_x();
		uint64 sy = video.size_y();

		OpticalFlowType forward_flows(sx,sy,Nframes);
		OpticalFlowType backward_flows(sx,sy,Nframes);

		// Read forward optical flows
		for (uint64 k = i; k <= end-1; k++) {
			std::ostringstream os;
			os << path << "/flows/flow_" << k << "_" << k+1 << ".flo";
			OpticalFlowFrame flow = forward_flows.frame(k-i);
			optical_flow::read_optical_flow(flow, os.str());  // read flow k,k+1 and put it to the position k-i of the current block
		}

		// Read backward optical flows
		for (uint64 k = i+1; k <= end; k++) {
			std::ostringstream os;
			os << path << "/flows/flow_" << k << "_" << k-1 << ".flo";
			OpticalFlowFrame flow = backward_flows.frame(k-i);
			optical_flow::read_optical_flow(flow, os.str()); // read flow k,k-1 and put it to the position k-i of the current block
		}

		// Put the backward flows to the last frame so we can use flow information for segmentation (for tracking it is not needed)
		for (OpticalFlowType::frame_iterator p = forward_flows.frame_begin(Nframes-1); p != forward_flows.frame_end(Nframes-1); ++p) {
			(*p) = backward_flows(p.pos());
		}


		// Perform first BPT with motion mean

		PartitionType p(video.sizes());
		BPTAlgorithm1::Parameters pars;
		BPTAlgorithm1::StopConditionType::Parameters stop_pars;

		stop_pars.num_regions_to_stop = 200; //sx*sy*Nframes / 100; // average size of 100 voxels

		pars.stop_parameters = stop_pars;
		pars.debug = true;
		pars.step = 0.1;
		pars.update_roots_partition = true;

		float64 motion_damping = pmotion * estimate_motion_damping(forward_flows);
		float64 color_damping = pcolor * estimate_color_damping(video);

		// output motion regularizer

		std::cout << "Maximum local color distance " << color_damping/pcolor << " setting at " << color_damping << std::endl;
		std::cout << "Maximum local motion distance " << motion_damping/pmotion << " setting at " << motion_damping << std::endl;

		optical_flow::TrajectoryTracking<VideoType, OpticalFlowType, PartitionType>::Parameters tracker_pars;
		tracker_pars.occlusion_lambda = 1;
		tracker_pars.variation_lambda = 1;
		tracker_pars.structure_lambda = 1;
		tracker_pars.color_lambda = 14;

		optical_flow::TrajectoryTracking<VideoType, OpticalFlowType, PartitionType> tracker(video,tracker_pars);

		p = tracker.calculate(video,forward_flows, backward_flows);

		toolbox::TicToc t;
		t.tic();
		BPTAlgorithm1 bpt_motion_color(pars);

		MeanDistanceModelType::Parameters model_pars;
		model_pars.optical_flow = forward_flows;
		model_pars.color_damping = 1/color_damping;
		model_pars.motion_damping = 1/motion_damping;
		model_pars.spatial_damping = 1;
		model_pars.area_damping = 1;
		model_pars.num_colors = 8;

		model_pars.flow_reliability = tracker.flow_reliability();

		VideoSignal<float64,1> var = tracker.flow_variation();
		VideoSignal<float64,1> str = tracker.structure_tensor();
		VideoSignal<float64,1> occ = tracker.flow_occlusions();
		VideoSignal<float64,1> rel = tracker.flow_reliability();

		VideoType flow_map_img 			= convert_map_to_image(var);
		VideoType flow_occ_img 			= convert_map_to_image(occ);
		VideoType structure_map_img 	= convert_map_to_image(str);
		VideoType flow_rel_img			= convert_map_to_image(rel);

		for (uint64 k = 0; k < flow_map_img.length(); k++) {
			std::ostringstream os;
			os << result_path.string() << "/occlusions/" << std::setw(5) << std::setfill('0') << k+i << ".png";
			flow_occ_img.write_frame(os.str(),k); // read frame k and put it to the position k-i of the current block
		}

		for (uint64 k = 0; k < flow_map_img.length(); k++) {
			std::ostringstream os;
			os << result_path.string() << "/flow_variation/" << std::setw(5) << std::setfill('0') << k+i << ".png";
			flow_map_img.write_frame(os.str(),k); // read frame k and put it to the position k-i of the current block
		}

		for (uint64 k = 0; k < flow_map_img.length(); k++) {
			std::ostringstream os;
			os << result_path.string() << "/structure_tensor/" << std::setw(5) << std::setfill('0') << k+i << ".png";
			structure_map_img.write_frame(os.str(),k); // read frame k and put it to the position k-i of the current block
		}

		for (uint64 k = 0; k < flow_map_img.length(); k++) {
			std::ostringstream os;
			os << result_path.string() << "/flow_reliability/" << std::setw(5) << std::setfill('0') << k+i << ".png";
			//std::cout << result_path.string() << "/flow_reliability/" << std::setw(5) << std::setfill('0') << k << ".png" << std::endl;
			flow_rel_img.write_frame(os.str(),k); // read frame k and put it to the position k-i of the current block
		}

		bpt_motion_color.init(video, p);

		BPT& bpt1 = bpt_motion_color.bpt();

		if (type == 1)
			add_temporal_neighbors(video, bpt1, forward_flows, backward_flows, bpt1.leaves_partition(),type);

		//while(true);

		// print trajectories
		converter.convert(video, ColorSpaceRGB);
		VideoType trajectories = print_trajectories(video, bpt1.leaves_partition(), bpt1);
		for (uint64 k = 0; k < flow_map_img.length(); k++) {
			std::ostringstream os;
			os << result_path.string() << "/trajectories/" << std::setw(5) << std::setfill('0') << k+i << ".png";
			trajectories.write_frame(os.str(),k); // read frame k and put it to the position k-i of the current block
		}
		converter.convert(video, ColorSpaceLAB);

		bpt_motion_color.create<MeanDistanceModelType>(video, model_pars);

		std::cout << "Oversegmentation with " << bpt_motion_color.num_regions() << " regions" << std::endl;

		bpt_motion_color.manager().clear_descriptors(video);

		// Perform second BPT
		PartitionType p2 = bpt1.roots_partition();
		BPTAlgorithm2::Parameters pars2;
		BPTAlgorithm2::StopConditionType::Parameters stop_pars2;

		// output oversegmentation
		VideoType over_segmentation = segmentation::to_false_color<VideoType>(p2);

		for (uint64 k = 0; k < Nframes; k++) {
			std::ostringstream os;
			os << result_path << "/over_segmentation/" << std::setw(5) << std::setfill('0') << k << ".png";
			FrameType frame = over_segmentation.frame(k);
			frame.write(os.str());
		}

		stop_pars2.num_regions_to_stop = 1;

		pars2.stop_parameters = stop_pars2;
		pars2.debug = true;
		pars2.step = 0.1;
		pars2.update_roots_partition = true;

		HistDistanceModelType::Parameters model_pars2;
		model_pars2.optical_flow = forward_flows;
		model_pars2.color_damping = 1/color_damping;
		model_pars2.motion_damping = 1/motion_damping;
		model_pars2.spatial_damping = 1;
		model_pars2.area_damping = 1;
		model_pars2.num_colors = 8;
		model_pars2.flow_reliability = tracker.flow_reliability();

		BPTAlgorithm2 bpt_motion_hist_color(pars2);
		bpt_motion_hist_color.init(video, p2);
		BPT& bpt2 = bpt_motion_hist_color.bpt();

		if (type == 1)
			add_temporal_neighbors(video, bpt2, forward_flows, backward_flows, bpt2.leaves_partition(),type);

		bpt_motion_hist_color.create<HistDistanceModelType>(video, model_pars2);

		std::cout << "Saving tree..." << std::endl;
		bpt2.save_to_files(result_path.string() + "/leaves.sgm", result_path.string() + "/mergings.txt");

		t.toc(true);
	}


}
